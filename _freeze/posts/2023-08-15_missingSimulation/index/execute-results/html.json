{
  "hash": "6edbd0ff5511f79783874bad0b80fa01",
  "result": {
    "markdown": "---\ntitle: \"Simulation task: recovering causal effects from post-treatment selection induced by missing outcome data\"\ndescription: \"A simulation exercise on missing data, selection bias, causal inference and TMLE\"\ndate: \"2023-08-15\"\ncategories: [selection bias, mediation, regression, IPW, doubly-robust, TMLE]\nfontsize: 11pt\nformat: \n  html:\n    fig-width: 7.5\n    fig-height: 4\n    fig-align: center\n    code-fold: true\n    toc: true\nbibliography: references.bib\nimage: logo.png\n---\n\n\n------------------------------------------------------------------------\n\n## Objective\n\nThe final goal is to estimate [the effects of ADHD treatment on school performance]{style=\"color:blue;\"}, where:\n\n- **the estimands**: average treatment effect (ATE) and conditional average treatment effect (CATE)\n- **the exposure**: stimulant medication for ADHD\n- **the outcome**: raw score at the mathematics national test at grade 8\n- **the target population**: ADHD-diagnosed Norwegian schoolchildren between grades 6 and 8\n\nFor this task, we employ:\n\n- The structural causal models (SCM) framework [@PearlCausality]\n- A synthetic **observational** dataset, generated by an SCM learnt from real-world data (functional mechanisms are treated as unknown in the analysis)\n- A back-door admissible set of pre-treatment variables; i.e., the assumption of no latent confounding\n- A missing-outcome mechanism that allows recoverability via IPW and regression adjustment (functional specification is unknown in the analysis)\n- The targeted minimum-loss estimation (TMLE) framework [@TMLEbook1]\n\n## Synthetic data\n\nLet $\\mathcal{G}'$ be a directed acyclic graph (DAG) built from domain knowledge and temporal-order constraints, involving the exposure $A$, the outcome $Y$, a set of confounders $H$, and mediators $M$. We previously fit flexible models (random forests) to learn the causal mechanisms $\\hat{f}_V:\\text{supp}\\, \\text{pa}(V;\\mathcal{G}')\\times \\text{supp}\\, U_V\\rightarrow\\text{supp}\\, V$ from real-world data on the subject. This allows us to replicate such mechanisms to generate fake data from seeds (noises and exogenous variables) in a controlled environment, along with counterfactual outcomes. In this exercise, exogenous variables mimic the marginal distribution of their real-world counterpart, [but not the joint distribution]{style=\"color:blue;\"}.     \n\n> By design, conditional ignorability is satisfied in the synthetic system using the full confounder set. It might not be satisfied in the system where the real-world data come from.\n\nGenerated variables can be grouped in three categories:\n\n**1. Pre-treatment / exogenous variables and the exposure**:\n\n-   `mom.vuln` = $H_1\\in\\mathbb{R}$ = maternal *vulnerability* index: a PCA-based index summarizing mother's diagnoses (+), level of education (-), age (-), and number of children (-)\n-   `sex.girl` = $H_2\\in\\{0,1\\}$ = child's sex at birth, female = 1\n-   `med.pre6` = $H_3\\in\\{0,1\\}$ = prescription for ADHD medication before grade 6\n-   `pre.diag` = $H_4\\in\\{0,1\\}$ = diagnoses for comorbid disorders (ADHD-related, internalizing or externalizing) registered before grade 6\n-   `ntr.grd5` = $H_5\\in\\mathbb{R}$ = raw score obtained at the national test for grade 5 (average math and reading)\n-   `reg.gpsp` = $H_6\\in\\mathbb{N}$ = number of registrations for health services (GP and specialist) before grade 6\n-   `med.6to8` = $A$ = prescription for ADHD medication between grades 6-8\n\n**2. Mediator variables and the outcome**:\n\n-   `ptr.diag` = $M_1\\in\\{0,1\\}$ = diagnoses for comorbid disorders (ADHD-related, internalizing or externalizing) registered between grades 6-8\n-   `ptr.gpsp` = $M_2\\in\\mathbb{N}$ = number of registrations for health services (GP and specialist) between grades 6-8\n-   `ntr.grd8` = $Y$ = raw score obtained at the national test for grade 8 (math)\n\n**3. Counterfactual variables**:\n\n-   `ptr.diag.cntr` = $M_1^{1-A}$ = diagnoses for comorbid disorders (ADHD-related, internalizing or externalizing) registered between grades 6-8, *had the individual taken the opposite treatment*\n-   `ptr.gpsp.cntr` = $M_2^{1-A}$ = number of registrations for health services (GP and specialist) between grades 6-8, *had the individual taken the opposite treatment*\n-   `ntr.grd8.cntr` = $Y^{1-A}$ = raw score obtained at the national test for grade 5 (math)\n-   `ITE` = $Y^{1}-Y^{0}$ = individual treatment effect\n\nA dataset (`synth.data`) of $N=5\\,000$ samples was generated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages --------------------------------------------------------------\nlibrary(data.table)   # Processes dataframes\nlibrary(dplyr)        # Processes dataframes\nlibrary(kableExtra)   # Styles tables\nlibrary(speedglm)     # Performs fast fitting for GLM\nlibrary(ranger)       # Performs random forest learning\nlibrary(nnls)         # Performs non-negative least squares\nlibrary(Rsolnp)       # Augmented Lagrange optimizer\nlibrary(sl3)          # Performs super-learning\nlibrary(tmle3)        # Performs TMLE\nlibrary(tmle3mediate) # Performs TMLE for mediation analysis\nlibrary(ggplot2)      # Plots\n\n# Read data -------------------------------------------------------------------\nload(file=\"syntheticADHDdata.RData\")\n\n# Glimpse of the data ---------------------------------------------------------\nsynth.data = data.table(synth.data)\nsynth.data %>% head() %>% kable(caption = \"Table 1: A glimpse at the synthetic data\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n<caption>Table 1: A glimpse at the synthetic data</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> mom.vuln </th>\n   <th style=\"text-align:right;\"> sex.girl </th>\n   <th style=\"text-align:right;\"> med.pre6 </th>\n   <th style=\"text-align:right;\"> pre.diag </th>\n   <th style=\"text-align:right;\"> ntr.grd5 </th>\n   <th style=\"text-align:right;\"> reg.gpsp </th>\n   <th style=\"text-align:right;\"> med.6to8 </th>\n   <th style=\"text-align:right;\"> ptr.diag </th>\n   <th style=\"text-align:right;\"> ptr.gpsp </th>\n   <th style=\"text-align:right;\"> ntr.grd8 </th>\n   <th style=\"text-align:right;\"> ptr.diag.cntr </th>\n   <th style=\"text-align:right;\"> ptr.gpsp.cntr </th>\n   <th style=\"text-align:right;\"> ntr.grd8.cntr </th>\n   <th style=\"text-align:right;\"> ITE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 0.65 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 19.64 </td>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 42 </td>\n   <td style=\"text-align:right;\"> 16.77 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 44 </td>\n   <td style=\"text-align:right;\"> 19.29 </td>\n   <td style=\"text-align:right;\"> 2.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1.31 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 25.85 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 26.72 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:right;\"> 21.64 </td>\n   <td style=\"text-align:right;\"> 5.08 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 19.59 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:right;\"> 21.38 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 46 </td>\n   <td style=\"text-align:right;\"> 23.27 </td>\n   <td style=\"text-align:right;\"> 1.89 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 0.65 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 15.12 </td>\n   <td style=\"text-align:right;\"> 23 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 17.62 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 14.48 </td>\n   <td style=\"text-align:right;\"> 3.14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 0.99 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 9.30 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 15.02 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:right;\"> 15.16 </td>\n   <td style=\"text-align:right;\"> 0.14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.02 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 19.83 </td>\n   <td style=\"text-align:right;\"> 128 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 47 </td>\n   <td style=\"text-align:right;\"> 19.62 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 75 </td>\n   <td style=\"text-align:right;\"> 20.18 </td>\n   <td style=\"text-align:right;\"> 0.56 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## No missingness case\n\nA known SCM allows the computation of unit-level counterfactuals: we can see both worlds at the same time. In particular, we can compute the oracle *sample average treatment effect* ($^S$ATE): the within-sample average of the *individual treatment effects* (unobserved in real-world data). \n$$\n^S\\text{ATE} = N^{-1}\\sum_{i=1}^N \\text{ITE}^{(i)} = N^{-1}\\sum_{i=1}^N (Y^{(i)}_{A=1}-Y^{(i)}_{A=0})\n$$\nThe $^S$ATE is itself a consistent (but impossible) estimator of the *population* ATE ($^P$ATE).\n\nLikewise, we can compute the oracle $^S$CATE for $X$-specific effects. If $X$ is categorical, we can partition units into strata: $I(x):=\\{i\\in 1\\dots N : X^{(i)}=x\\}$.\n$$\n^S\\text{CATE}(x) = |I(x)|^{-1}\\sum_{i\\in I(x)} \\text{ITE}^{(i)} = |I(x)|^{-1}\\sum_{i\\in I(x)} (Y^{(i)}_{A=1}-Y^{(i)}_{A=0})\n$$\n\nLet us compare the oracle effects against the results from two approaches:\n\n- $t$-tests comparing the means of raw test scores between treated and non-treated. This estimator would be biased due to confounding\n\n- The TMLE estimator using **super-learners** [@superlearners2023], combining:\n    + flexible libraries of **base-learners** to model $A$ and $Y$ given confounders $H$. We employ linear models and random forests (ground-truth DGP is in this model-space)\n    \n    + **meta-learners**: to ensemble the base-learners together, weighted by their **out-of-sample** (CV) predictive measures to avoid over-fitting (logit for $A$ and NNLS for $Y$) \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n###############################################################################\n# Solution via t-tests (biased by confounding)\n###############################################################################\n\n# Function to generate C.I. data from t-tests ---------------------------------\n# Param: pre-treatment binary variable to stratify\n# Return: data ready to plot as confidence intervals\n\nget.ci.data = function(varname){\n  \n  # Temporal data.frame\n  dplot1 = synth.data\n  dplot1$dummy = dplot1[,get(varname)]\n    \n  # Two-sample t-test: biased! -------------------\n  \n  # all, med vs no-med\n  ttest.pop = t.test(dplot1[med.6to8==1, ntr.grd8], # treated\n                     dplot1[med.6to8==0, ntr.grd8]) # control\n  # subpop 0, med vs no-med\n  ttest.sp0 = t.test(dplot1[med.6to8==1 & dummy==0, ntr.grd8], # treated (sp 0)\n                     dplot1[med.6to8==0 & dummy==0, ntr.grd8]) # control (sp 0)\n  # subpop 1, med vs no-med\n  ttest.sp1 = t.test(dplot1[med.6to8==1 & dummy==1, ntr.grd8], # treated (sp 1)\n                     dplot1[med.6to8==0 & dummy==1, ntr.grd8]) # control (sp 1)\n\n  # One-sample t-test: oracle! -------------------\n  \n  # oracle ITE, all\n  otest.pop = t.test(dplot1[, ITE])            \n  # oracle ITE, subpop 0\n  otest.sp0 = t.test(dplot1[dummy==0, ITE])    \n  # oracle ITE, subpop 1\n  otest.sp1 = t.test(dplot1[dummy==1, ITE])    \n  \n  # data frame put together ----------------------\n  \n  dplot1 = data.table( \n    # label for type of analysis\n    type = rep(c('t-test','oracle'), each=3),\n    # label for supopulation\n    subpop = rep(c('all','subpop 0','subpop 1'), 2),        \n    # lower bound\n    low = c(ttest.pop$conf.int[1], ttest.sp0$conf.int[1], ttest.sp1$conf.int[1],  \n            otest.pop$conf.int[1], otest.sp0$conf.int[1], otest.sp1$conf.int[1]),\n    # upper bound\n    upr = c(ttest.pop$conf.int[2], ttest.sp0$conf.int[2], ttest.sp1$conf.int[2],  \n            otest.pop$conf.int[2], otest.sp0$conf.int[2], otest.sp1$conf.int[2]))\n  \n  # add midpoint and return dataframe\n  dplot1 = dplot1[, midp := (low+upr)/2] \n  return(dplot1)                          \n}\n\n###############################################################################\n# Solution via adjusted regression / TMLE\n###############################################################################\n\n# Learning algorithms employed to learn treatment/outcome mechanisms -----------\n\n# Linear model\nlrnr_lm = make_learner(Lrnr_glm_fast)\n# Random forest model\nlrnr_rf = make_learner(Lrnr_ranger)      \n\n# Meta-learners: to stack together predictions from the learners ---------------\n\n# Combine Y predictions with non-negative least squares\nmeta_Y = make_learner(Lrnr_nnls)   \n\n# Combine A predictions with logit likelihood (augmented Lagrange optimizer)\nmeta_A = make_learner(Lrnr_solnp,                     \n  loss_function = loss_loglik_binomial,              \n  learner_function = metalearner_logistic_binomial)   \n\n# Super-learners: learners + meta-learners together ----------------------------\n\n# Outcome super-learning\nsuper_Y = Lrnr_sl$new(learners = list(lrnr_lm, lrnr_rf), \n                      metalearner = meta_Y)\n# Exposure super-learning\nsuper_A = Lrnr_sl$new(learners = list(lrnr_lm, lrnr_rf), \n                      metalearner = meta_A)\n# Super-learners put together\nsuper_list = list(A = super_A,\n                  Y = super_Y)              \n\n# Confounder set labels\nH = colnames(synth.data[,1:6])\n\n# Function to generate C.I. data from TMLE--------------------------------------\n# Param: pre-treatment binary variable to stratify\n# Param: data\n# Return: data from confidence intervals\n\naux_tml_method = function(namevar, data=synth.data){\n  tmle_CATE = tmle3(\n  tmle_spec = tmle_stratified(tmle_ATE(1,0)), # Causal contrast CATE: Y1-Y0\n  node_list = list(                           # Variables involved in the query\n    W = setdiff(H,namevar),                   # Label for non-stratum confounders\n    V = namevar,                              # Label for stratifying variable\n    A = \"med.6to8\",                           # Label for exposure\n    Y = \"ntr.grd8\"),                          # Label for outcome\n  data = data,                                # Data\n  learner_list = super_list)                  # Super-learners specified\n  return(tmle_CATE$summary)                   # Return summary\n}\n\n###############################################################################\n# Generate confidence intervals to plot\n###############################################################################\n\n# t-test on prior treatment\nttest.med = cbind.data.frame(get.ci.data('med.pre6'),  # C.I. data\n                             strata='prior treatment') # Strata variable\n\n# t-test on sex strata\nttest.sex = cbind.data.frame(get.ci.data('sex.girl'), # C.I. data\n                             strata='sex at birth')   # Strata variable\n\n# TMLE on prior treatment\ntml.cate.med = aux_tml_method('med.pre6')                                       # TMLE results\ntlme.med = cbind.data.frame(type='TMLE',                                        # method label\n                            subpop=c('all','subpop 0','subpop 1'),              # subpop label\n                            tml.cate.med[order(tml.cate.med$param),c(9,10,8)],  # C.I. data\n                            strata='prior treatment')                           # Strata variable\n# TMLE on sex strata\ntml.cate.sex = aux_tml_method('sex.girl')                                       # TMLE results\ntlme.sex = cbind.data.frame(type='TMLE',                                        # method label\n                            subpop=c('all','subpop 0','subpop 1'),              # subpop label\n                            tml.cate.sex[order(tml.cate.sex$param),c(9,10,8)],  # C.I. data\n                            strata='sex at birth')                              # Strata variable\n\n# Unify column names\ncolnames(tlme.med) = colnames(ttest.med)\ncolnames(tlme.sex) = colnames(ttest.sex)\n\n# Put all together\nci.data.1 = rbind.data.frame(ttest.med, ttest.sex, tlme.med, tlme.sex)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nThe following plot presents the point-estimate and 95\\% confidence interval for the ATE/CATE resulting from oracle $^S$ATE/$^S$CATE, $t$-tests, and TMLE.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Plot confidence intervals ---------------------------------------------------\nci.data.1 %>% \n  ggplot(aes(x = subpop, y = midp, colour = type)) +                    \n  geom_errorbar(aes(ymax = upr, ymin = low), position = \"dodge\") +\n  geom_point(position = position_dodge(0.9)) +\n  geom_hline(yintercept=0, linetype=\"dashed\", color = \"red\") +\n  labs(y='ATE/CATE estimate',\n       x='Subpopulation (1 = yes prior treatment, 1 = girls)') +\n  facet_wrap(~strata) + theme_classic()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=768}\n:::\n:::\n\n\nFrom the previous plot we can infer:\n\n**1. There is some amount of confounding**\n    \n- Confidence intervals from $t$-tests ([green]{style=\"color:green;\"}) do not always cover the sample-based oracle value ([red]{style=\"color:red;\"}). This is probably due to confounding bias, as $t$-test do not adjust for covariation with $H$\n    \n- In general, confounding bias is negative: unadjusted effects are below the oracle result\n    \n- Confounding bias seems to be particularly problematic when stratifying on prior prescription for ADHD medication, which might be a strong predictor of the exposure\n    \n- $t$-test results might lead to conclude that the treatment is actually **deleterious** for those who had not started it before grade 6 (because of late diagnosis?). In fact, the treatment has positive, but extremely small, average effect in such subpopulation \n\n- $t$-test results might also lead to conclude that the treatment effect is **insignificant** for boys. In fact, the effect on them is small but positive \n\n**2. TMLE with covariate adjustment**\n    \n- Under some mild condition including back-door admissibility of $H$, TMLE produces consistent estimators. This is, the amount of confounding bias becomes negligible in large finite samples. We can see that confidence intervals from TMLE ([blue]{style=\"color:blue;\"}) cover the sample-based oracle value ([red]{style=\"color:red;\"}) in all cases\n\n- TMLE results lead to correct interpretation of treatment effect for boys and the subpopulation who did not start treatment before grade 6\n\n[3. In general, the effects of ADHD treatment on school performance are **positive but small**]{style=\"color:blue;\"}\n\n- [The estimate ATE is 1.7, on an outcome with mean 21.0 and standard deviation 7.0]{style=\"color:blue;\"}\n\n\n## Outcome-missingness mechanisms\n\nLet us simulate the $Y$-missingness mechanism as a binary random variable $R_Y$, childless in the associated $m$-graph $\\mathcal{G}$. For a particular individual $i$, $R_Y^{(i)}=1$ indicates that its respective outcome realization $Y^{(i)}$ is observed, while $R_Y^{(i)}=0$ signifies $Y^{(i)}$ is missing. This mechanism has a probit specification:\n\n$$\nR_Y = \\mathbb{I}[\\theta_0 + \\theta_H^\\top H + \\theta_A A + \\theta_M^\\top M + U_R > 0],\\quad U_R\\sim N(0,1)\n$$\n\nFixing the parameters $\\theta$ to certain value (unknown in the analysis), a realization of $U_R$ produces 751 (15\\%) missing outcomes:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n###############################################################################\n# Building an endogenous selection/missingness mechanism\n###############################################################################\n\n# Parameter for the glm-probit specification, only main effects\nset.seed(9)\nnoise.R = rnorm(n=5e3, 0, 1)\ntheta.i = 3.77 \ntheta.c = c(-0.01, -1.97, -2.03, 0.18, -0.03, 0.01, -0.05, 0.64, -0.01)\nlin.pred = as.matrix(synth.data[,1:9]) %*% theta.c + theta.i + noise.R\n\n# Realization of missingness mechanism\nsynth.data$RY = ifelse(lin.pred > 0, 1, 0)\n\n# Count how many selected / observed -------------------------------------------\ntable(synth.data$RY) %>% \n  kable(col.names = c(\"R(Y)\",\"n\"),\n    caption = \"Table 2: Missing/selected unit-outcomes\",\n    table.attr = \"quarto-disable-processing=true\") %>% \n  kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table quarto-disable-processing=\"true\" class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Table 2: Missing/selected unit-outcomes</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> R(Y) </th>\n   <th style=\"text-align:right;\"> n </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:right;\"> 751 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 4249 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nUnder the TMLE framework, let us first consider four options to recover the ATE/CATE:\n\n1. **[TMLE-cc]{style=\"color:brown;\"}**: TMLE with complete cases. We discard entire units with $R_Y=0$ \n    \n    - This approach would produce a consistent estimator under MCAR. However, as $R_Y$ is MAR in our case, results would be biased \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n###############################################################################\n# Complete-case analysis for TMLE\n###############################################################################\n\n# TMLE on prior treatment\ntml.cate.med.cc = aux_tml_method('med.pre6',                                            \n                                 data=synth.data[RY==1,])                               # TMLE results\ntlme.med.cc = cbind.data.frame(type='TMLE-cc',                                          # method label\n                               subpop=c('all','subpop 0','subpop 1'),                   # subpop label\n                               tml.cate.med.cc[order(tml.cate.med.cc$param),c(9,10,8)], # C.I. data\n                               strata='prior treatment')                                # Strata variable\n# TMLE on sex strata\ntml.cate.sex.cc = aux_tml_method('sex.girl',\n                                 data=synth.data[RY==1,])                               # TMLE results\ntlme.sex.cc = cbind.data.frame(type='TMLE-cc',                                          # method label\n                               subpop=c('all','subpop 0','subpop 1'),                   # subpop label\n                               tml.cate.sex.cc[order(tml.cate.sex.cc$param),c(9,10,8)], # C.I. data\n                               strata='sex at birth')                                   # Strata variable\n```\n:::\n\n\n2. **[TMLE-im]{style=\"color:green;\"}**: TMLE with single median-inputation. We replace $Y^*$ with the median of the observed $Y$\n    \n    - This approach would also produce biased results, as all missing slots are inputed with the same numeric value independen of $H,A$. One preferable approach would be **multiple model-based inputations** (consistent under MAR). Yet, single median-inputation is [the built-in preprocessing method in the `tmle` package ](https://tlverse.org/tmle3/reference/process_missing.html)\n    \n    $$\n    Y^* \\leftarrow \\text{med}(Y\\mid R_Y=1)\n    $$\n    \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n###############################################################################\n# Median-based single imputation for missing outcome\n###############################################################################\n\n# Replace Y-values for NA whenever R(Y)=0\nobserved.data = copy(synth.data)\nobserved.data$ntr.grd8 = ifelse(observed.data$RY==0, NA, observed.data$ntr.grd8)\n\n# Apply process_missing function on TMLE package\nprocessed = process_missing(observed.data,                     # data\n                            node_list = list(W = H,            # confounders\n                                             A = \"med.6to8\",   # exposure\n                                             Y = \"ntr.grd8\"),  # outcome\n                            complete_nodes = c('W','A'))       # complete variables\n\n# TMLE on prior treatment\ntml.cate.med.im = aux_tml_method('med.pre6',\n                                 data=processed$data)                                   # TMLE results\ntlme.med.im = cbind.data.frame(type='TMLE-im',                                          # method label\n                               subpop=c('all','subpop 0','subpop 1'),                   # subpop label\n                               tml.cate.med.im[order(tml.cate.med.im$param),c(9,10,8)], # C.I. data\n                               strata='prior treatment')                                # Strata variable\n# TMLE on sex strata\ntml.cate.sex.im = aux_tml_method('sex.girl',\n                                 data=processed$data)                                   # TMLE results\ntlme.sex.im = cbind.data.frame(type='TMLE-im',                                          # method label\n                               subpop=c('all','subpop 0','subpop 1'),                   # subpop label\n                               tml.cate.sex.im[order(tml.cate.sex.im$param),c(9,10,8)], # C.I. data\n                               strata='sex at birth')                                   # Strata variable\n\n# Unify column names\ncolnames(tlme.med.cc) = colnames(ttest.med)\ncolnames(tlme.sex.cc) = colnames(ttest.sex)\ncolnames(tlme.med.im) = colnames(ttest.med)\ncolnames(tlme.sex.im) = colnames(ttest.sex)\n\n# Put all together\nci.data.2 = rbind.data.frame(ttest.med[ttest.med$type=='oracle',],\n                             ttest.sex[ttest.sex$type=='oracle',],\n                             tlme.med.cc, tlme.sex.cc,\n                             tlme.med.im, tlme.sex.im)\n```\n:::\n\n\n3. **[TMLE-mm]{style=\"color:blue;\"}**: TMLE with explicit model for $M$ (only considering `ptr.diag`)\n    \n    - Let us assume we are sure that post-treatment diagnoses (`ptr.diag`) have a direct effect on attrition, but post-treatment visits (`ptr.gpsp`) do not. Since the variable `ptr.diag` is binary, we can pose an explicit model using a superlearner based on logistic regression. If such assumption is sound, this approach should remove most of the selection bias. \n    \n    $$\n    \\begin{aligned}\n    &\\text{Outcome model on selected } & Q_1(H,A,M) = \\mathbb{E}[Y\\mid H,A,M,R_Y=1] & \\\\\n    &\\text{M-model (\\texttt{ptr.diag})}  & m(H,A) = \\mathbb{P}[M=1\\mid H,A] &\\\\\n    &\\text{M-averaged expected outcome}  & Q_2(H,a) = m(H,a)Q_1(H,a,1) +(1-m(H,a))Q_1(H,a,0) &\\\\\n    &\\text{Initial ATE} &  \\psi_0 = \\mathbb{E}_H\\Delta_a Q_2(H,a)&\\\\\n    &\\text{Propensity score (nuisance)}  & e(H) = \\mathbb{P}[A=1\\mid H] &\\\\\n    &\\text{Selection score (nuisance)}  & s(H,A,M) = \\mathbb{P}[R_Y=1\\mid H,A,M] &\\\\\n    \\end{aligned}\n    $$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n###############################################################################\n# Recovering causal effect via regression and explicit M-model\n###############################################################################\n\n# The library of base learners: GAM and random forests\nstack = Stack$new(Lrnr_gam$new(), Lrnr_ranger$new())\n\n# Super-learner for continuous outcome: NNLS\nsuperl = Lrnr_sl$new(learners = stack, metalearner = Lrnr_nnls$new())\n\n# Super-learner for binary variables: default logit\nsuperb = Lrnr_sl$new(learners = stack)\n\n# Function to generate C.I. data from TMLE--------------------------------------\n# Param: pre-treatment binary variable to stratify\n# Param: data\n# Return: data from confidence intervals\n\naux_tml_method_mmod = function(namevar, input.data){\n  \n  # Remove namevar from adjustment set\n  H = setdiff(H, namevar)\n  \n  # Learning the Q-function ---------------------------------------------------\n  \n  # Training task for Q, fit superlearner \n  # on selected-outcome data, including M1 as predictors\n  train.Q = make_sl3_Task(\n    data = input.data[RY==1,],\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag')\n  )\n  Q_fit = superl$train(task = train.Q)\n  \n  # Training task for M, all data\n  train.M = make_sl3_Task(\n    data = input.data,\n    outcome = 'ptr.diag',\n    covariates = c(H,'med.6to8')\n  )\n  M_fit = superb$train(task = train.M)\n  \n  # Case A=1 ------------------------------------------------------------------\n  \n  # Data to make counterfactual predictions \n  temp.dt = copy(input.data)\n  \n  # Prediction task for p(M=1 |A=1)\n  temp.dt$med.6to8 = 1\n  pred.M = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ptr.diag',\n    covariates = c(H,'med.6to8')\n  )\n  pM = M_fit$predict(task = pred.M)\n  \n  # Prediction task for E(Y |A=1, M=1)\n  temp.dt$ptr.diag = 1\n  pred.Q1 = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag')\n  )\n  \n  # Prediction task for E(Y |A=1, M=0)\n  temp.dt$ptr.diag = 0\n  pred.Q0 = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag')\n  )\n  \n  # Save INTEGRAL dP(M |A=1) E(Y |A=1, M)\n  input.data$Q_1m = pM * Q_fit$predict(task = pred.Q1) +\n    (1-pM) * Q_fit$predict(task = pred.Q0)\n  \n  # Case A=0 ------------------------------------------------------------------\n  \n  # Prediction task for p(M=1 |A=0)\n  temp.dt$med.6to8 = 0\n  pred.M = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ptr.diag',\n    covariates = c(H,'med.6to8')\n  )\n  pM = M_fit$predict(task = pred.M)\n  \n  # Prediction task for E(Y |A=0, M=1)\n  temp.dt$ptr.diag = 1\n  pred.Q1 = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag')\n  )\n  \n  # Prediction task for E(Y |A=0, M=0)\n  temp.dt$ptr.diag = 0\n  pred.Q0 = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag')\n  )\n  \n  # Save INTEGRAL dP(M |A=0) E(Y |A=0, M)\n  input.data$Q_0m = pM * Q_fit$predict(task = pred.Q1) +\n    (1-pM) * Q_fit$predict(task = pred.Q0)\n  \n  # Save Qm as the M-average of Q1 and Q0\n  input.data[,Qm := med.6to8*Q_1m + (1-med.6to8)*Q_0m]\n  \n  # Nuisance parameters: A  ----------------------------------------------------\n  \n  # Training task for A, fit superlearner \n  train.A = make_sl3_Task(\n    data = input.data,\n    outcome = 'med.6to8',\n    covariates = H\n  )\n  A_fit = superb$train(task = train.A)\n  input.data$p.score = A_fit$predict(task = train.A)\n  \n  # Nuisance parameters: R(Y)  -------------------------------------------------\n  \n  # Training task for R(Y), fit superlearner \n  train.R = make_sl3_Task(\n    data = input.data,\n    outcome = 'RY',\n    covariates = c(H,'med.6to8','ptr.diag')\n  )\n  R_fit = superb$train(task = train.R)\n  input.data$p.select = R_fit$predict(task = train.R)\n  \n  # Count parameters  ---------------------------------------------------------\n  N = nrow(input.data)\n  n = nrow(input.data[RY==1,])\n  r = n/N\n  \n  # Nuisance parameters: R(Y)  ---------------------------------------------------\n  input.data[, H:= r/(p.select) * (med.6to8/p.score - (1-med.6to8)/(1-p.score)) ]\n  \n  # Updating model  ---------------------------------------------------\n  updating = lm(ntr.grd8 ~ -1 + offset(Qm) + H, data=input.data)\n  eps = as.numeric(coef(updating))\n  \n  # Update Q-values\n  input.data[, Q_1f:= Q_1m + eps * r/(p.select*p.score)]\n  input.data[, Q_0f:= Q_0m - eps * r/(p.select*(1-p.score))]\n  input.data[, D:= H*(ntr.grd8 - Qm) + Q_1m - Q_0m]\n  \n  # Compute ATE, standard errors and CI\n  ate = mean(input.data$Q_1f - input.data$Q_0f)\n  ate.se = sd(input.data$D, na.rm=T)/sqrt(n)\n  ate.lo = ate - qnorm(0.975)*ate.se\n  ate.up = ate + qnorm(0.975)*ate.se\n  \n  # Return CI\n  return(c(ate.lo, ate.up, ate))\n}\n\n# Generate CI data\nate = aux_tml_method_mmod('', observed.data)\ncate.nop =  aux_tml_method_mmod('med.pre6', observed.data[med.pre6==0,])\ncate.yes =  aux_tml_method_mmod('med.pre6', observed.data[med.pre6==1,])\ncate.boy =  aux_tml_method_mmod('sex.girl', observed.data[sex.girl==0,])\ncate.grl =  aux_tml_method_mmod('sex.girl', observed.data[sex.girl==1,])\n\n# Put all together\nci.data.3 = ci.data[13:18,]\nci.data.3$type = 'TMLE-mm'\nci.data.3$midp = c(ate[3], cate.nop[3], cate.yes[3], ate[3], cate.boy[3], cate.grl[3])\nci.data.3$low = c(ate[1], cate.nop[1], cate.yes[1], ate[1], cate.boy[1], cate.grl[1])\nci.data.3$upr = c(ate[2], cate.nop[2], cate.yes[2], ate[2], cate.boy[2], cate.grl[2])\n```\n:::\n\n    \n4. **[TMLE-nr]{style=\"color:purple;\"}**: TMLE with nested regressions.\n    \n    - Let us assume we are sure that post-treatment diagnoses (`ptr.diag`) have a direct effect on attrition, but post-treatment visits (`ptr.gpsp`) do not. Since the variable `ptr.diag` is binary, we can pose an explicit model using a superlearner based on logistic regression. If such assumption is sound, this approach should remove most of the selection bias. \n    \n    $$\n    \\begin{aligned}\n    &\\text{Outcome model on selected } & Q_1(H,A,M) = \\mathbb{E}[Y\\mid H,A,M,R_Y=1] & \\\\\n    &\\text{High-level regression}  & Q_2(H,a) = \\mathbb{E}[\\hat{Q}_1\\mid H,A=a] &\\\\\n    &\\text{Initial ATE} &  \\psi_0 = \\mathbb{E}_H\\Delta_a Q_2(H,a)&\\\\\n    &\\text{Propensity score (nuisance)}  & e(H) = \\mathbb{P}[A=1\\mid H] &\\\\\n    &\\text{Selection score (nuisance)}  & s(H,A,M) = \\mathbb{P}[R_Y=1\\mid H,A,M] &\\\\\n    \\end{aligned}\n    $$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n###############################################################################\n# Recovering causal effect via nested regressions\n###############################################################################\n\n# Function to generate C.I. data from TMLE--------------------------------------\n# Param: pre-treatment binary variable to stratify\n# Param: data\n# Return: data from confidence intervals\n\naux_tml_method_nest = function(namevar, input.data){\n  \n  # Remove namevar from adjustment set\n  H = setdiff(H, namevar)\n  \n  # Learning the Q-function ---------------------------------------------------\n  \n  # Training task for Q, fit superlearner \n  # on selected-outcome data, including M1 as predictors\n  train.Q = make_sl3_Task(\n    data = input.data[RY==1,],\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag','ptr.gpsp')\n  )\n  \n  Q_fit = superl$train(task = train.Q)\n  \n  # Data to make counterfactual predictions \n  temp.dt = copy(input.data)\n  \n  # Prediction task for E(Y |A=1, M)\n  temp.dt$med.6to8 = 1\n  pred.Q1 = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag','ptr.gpsp')\n  )\n  \n  input.data$Q1.pred = Q_fit$predict(task = pred.Q1)\n  \n  # Prediction task for E(Y |A=0, M)\n  temp.dt$med.6to8 = 0\n  pred.Q0 = make_sl3_Task(\n    data = temp.dt,\n    outcome = 'ntr.grd8',\n    covariates = c(H,'med.6to8','ptr.diag','ptr.gpsp')\n  )\n  \n  input.data$Q0.pred = Q_fit$predict(task = pred.Q0)\n  \n  # Training task for Q21\n  train.Q21 = make_sl3_Task(\n    data = input.data,\n    outcome = 'Q1.pred',\n    covariates = H # No treatment in here, its fixed\n  )\n  Q21_fit = superl$train(task = train.Q21)\n  input.data$Q1.fin = Q21_fit$predict(task = train.Q21)\n  \n  # Training task for Q20\n  train.Q20 = make_sl3_Task(\n    data = input.data,\n    outcome = 'Q0.pred',\n    covariates = H # No treatment in here, its fixed\n  )\n  Q20_fit = superl$train(task = train.Q20)\n  input.data$Q0.fin = Q20_fit$predict(task = train.Q20)\n  \n  # m-Average\n  input.data[, Qa:= med.6to8*Q1.fin + (1-med.6to8)*Q0.fin]\n  \n  # Nuisance parameters: A  ----------------------------------------------------\n  \n  # Training task for A, fit superlearner \n  train.A = make_sl3_Task(\n    data = input.data,\n    outcome = 'med.6to8',\n    covariates = H\n  )\n  A_fit = superb$train(task = train.A)\n  input.data$p.score = A_fit$predict(task = train.A)\n  \n  # Nuisance parameters: R(Y)  -------------------------------------------------\n  \n  # Training task for R(Y), fit superlearner \n  train.R = make_sl3_Task(\n    data = input.data,\n    outcome = 'RY',\n    covariates = c(H,'med.6to8','ptr.diag')\n  )\n  R_fit = superb$train(task = train.R)\n  input.data$p.select = R_fit$predict(task = train.R)\n  \n  # Count parameters  ---------------------------------------------------------\n  N = nrow(input.data)\n  n = nrow(input.data[RY==1,])\n  r = n/N\n  \n  # Nuisance parameters: R(Y)  ---------------------------------------------------\n  input.data[, H:= r/(p.select) * (med.6to8/p.score - (1-med.6to8)/(1-p.score)) ]\n  \n  # Updating model  ---------------------------------------------------\n  updating = lm(ntr.grd8 ~ -1 + offset(Qa) + H, data=input.data)\n  eps = as.numeric(coef(updating))\n  \n  # Update Q-values\n  input.data[, Q_1f:= Q1.fin + eps * r/(p.select*p.score)]\n  input.data[, Q_0f:= Q0.fin - eps * r/(p.select*(1-p.score))]\n  input.data[, D:= H*(ntr.grd8 - Qa) + Q1.fin - Q0.fin]\n  \n  # Compute ATE, standard errors and CI\n  ate = mean(input.data$Q_1f - input.data$Q_0f)\n  ate.se = sd(input.data$D, na.rm=T)/sqrt(n)\n  ate.lo = ate - qnorm(0.975)*ate.se\n  ate.up = ate + qnorm(0.975)*ate.se\n  \n  # Return CI\n  return(c(ate.lo, ate.up, ate))\n}\n\n# Generate CI data\nate = aux_tml_method_nest('', observed.data)\ncate.nop =  aux_tml_method_nest('med.pre6', observed.data[med.pre6==0,])\ncate.yes =  aux_tml_method_nest('med.pre6', observed.data[med.pre6==1,])\ncate.boy =  aux_tml_method_nest('sex.girl', observed.data[sex.girl==0,])\ncate.grl =  aux_tml_method_nest('sex.girl', observed.data[sex.girl==1,])\n\n# Put all together\nci.data.4 = ci.data[13:18,]\nci.data.4$type = 'TMLE-nr'\nci.data.4$midp = c(ate[3], cate.nop[3], cate.yes[3], ate[3], cate.boy[3], cate.grl[3])\nci.data.4$low = c(ate[1], cate.nop[1], cate.yes[1], ate[1], cate.boy[1], cate.grl[1])\nci.data.4$upr = c(ate[2], cate.nop[2], cate.yes[2], ate[2], cate.boy[2], cate.grl[2])\n\n# All methods together\nci.data = rbind(ci.data.2, ci.data.3, ci.data.4)\n```\n:::\n\n\n\nThe following plot presents the point-estimate and 95% confidence interval from the approaches presented above:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Plot confidence intervals ---------------------------------------------------\nrbind(ci.data) %>% \n  ggplot(aes(x = subpop, y = midp, colour = type)) +                    \n  geom_errorbar(aes(ymax = upr, ymin = low), position = \"dodge\") +\n  geom_point(position = position_dodge(0.9)) +\n  geom_hline(yintercept=0, linetype=\"dashed\", color = \"red\") +\n  labs(y='ATE/CATE estimate',\n       x='Subpopulation (1 = yes prior treatment, 1 = girls)') +\n  facet_wrap(~strata) + theme_classic()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n**Regression adjustment works**\n    \n- Confidence intervals from complete-case analysis ([brown]{style=\"color:brown;\"}) and single median-inputations ([green]{style=\"color:green;\"}) fail to cover the oracle SATE  ([red]{style=\"color:red;\"}) in most cases, particularly for the population ATE. \n- A regression-based solution via an explicit model for `ptr.diag` ([blue]{style=\"color:blue;\"}) does a better job, and only struggle with small subpopulations in the data (no prior treatment or girls, about 30\\%). \n- A nested-regressions approach ([purple]{style=\"color:purple;\"}) performs well for the ATE, but struggle a little with small subpopulations. \n\n\nAll methods above via TMLE employ only one fluctuation parameter (on $Q_2$). Better performance can be obtained by working with a fluctuation parameter on $Q_1$ or $p(M\\mid H,A)$ as well, and by incorporating smart cross-fitting schemes.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}