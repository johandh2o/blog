@article{gruber2009targeted,
  title={Targeted Maximum Likelihood Estimation: A Gentle Introduction},
  author={Gruber, Susan and van der Laan, Mark J},
  journal={The American Statistician},
  volume={63},
  number={4},
  pages={1--38},
  year={2009},
  publisher={Taylor \& Francis}
}
@book{TMLEbook1,
  title={Targeted Learning: Causal Inference for Observational and Experimental Data},
  author={{van der Laan}, Mark J. and Rose, S.},
  isbn={9781441997821},
  lccn={2011930854},
  series={Springer Series in Statistics},
  url={https://books.google.no/books?id=RGnSX5aCAgQC},
  year={2011},
  publisher={Springer New York}
}
@article{vanderLaanNuisance,
	author = {Mark J. van der Laan},
	doi = {doi:10.1515/ijb-2012-0038},
	journal = {The International Journal of Biostatistics},
	lastchecked = {2023-09-18},
	number = {1},
	pages = {29--57},
	url = {https://doi.org/10.1515/ijb-2012-0038},
	volume = {10},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1515/ijb-2012-0038},
    title = {Targeted Estimation of Nuisance Parameters to Obtain Valid Statistical Inference}
}
@article{rcensoringTMLE,
	author = {van der Laan, Mark J. and Rubin, Daniel},
	journal = {Berkeley Division of Biostatistics Working Paper Series},
    volume = {Working Paper 226},
	url = {https://biostats.bepress.com/ucbbiostat/paper226},
	year = {2007},
    title = {A Note on Targeted Maximum Likelihood and Right Censored Data}
}
@article{hines2022demystifying,
  title={Demystifying statistical learning based on efficient influence functions},
  author={Hines, Oliver and Dukes, Oliver and Diaz-Ordaz, Karla and Vansteelandt, Stijn},
  journal={The American Statistician},
  volume={76},
  number={3},
  pages={292--304},
  year={2022},
  publisher={Taylor \& Francis}
}
@article{Smith2023,
    title = {Application of targeted maximum likelihood estimation in public health and epidemiological studies: a systematic review},
    journal = {Annals of Epidemiology},
    volume = {86},
    pages = {34-48.e28},
    year = {2023},
    issn = {1047-2797},
    doi = {https://doi.org/10.1016/j.annepidem.2023.06.004},
    url = {https://www.sciencedirect.com/science/article/pii/S1047279723001151},
    author = {Matthew J. Smith and Rachael V. Phillips and Miguel Angel Luque-Fernandez and Camille Maringe},
    keywords = {Targeted Maximum Likelihood Estimation (TMLE), Epidemiology, Observational studies, Causal inference, Systematic review},
    abstract = {Purpose
    The targeted maximum likelihood estimation (TMLE) statistical data analysis framework integrates machine learning, statistical theory, and statistical inference to provide a least biased, efficient, and robust strategy for estimation and inference of a variety of statistical and causal parameters. We describe and evaluate the epidemiological applications that have benefited from recent methodological developments.
    Methods
    We conducted a systematic literature review in PubMed for articles that applied any form of TMLE in observational studies. We summarized the epidemiological discipline, geographical location, expertize of the authors, and TMLE methods over time. We used the Roadmap of Targeted Learning and Causal Inference to extract key methodological aspects of the publications. We showcase the contributions to the literature of these TMLE results.
    Results
    Of the 89 publications included, 33% originated from the University of California at Berkeley, where the framework was first developed by Professor Mark van der Laan. By 2022, 59% of the publications originated from outside the United States and explored up to seven different epidemiological disciplines in 2021–2022. Double-robustness, bias reduction, and model misspecification were the main motivations that drew researchers toward the TMLE framework. Through time, a wide variety of methodological, tutorial, and software-specific articles were cited, owing to the constant growth of methodological developments around TMLE.
    Conclusions
    There is a clear dissemination trend of the TMLE framework to various epidemiological disciplines and to increasing numbers of geographical areas. The availability of R packages, publication of tutorial papers, and involvement of methodological experts in applied publications have contributed to an exponential increase in the number of studies that understood the benefits and adoption of TMLE.}
}
@article{superlearners2023,
    author = {Phillips, Rachael V and van der Laan, Mark J and Lee, Hana and Gruber, Susan},
    title = "{Practical considerations for specifying a super learner}",
    journal = {International Journal of Epidemiology},
    volume = {52},
    number = {4},
    pages = {1276-1285},
    year = {2023},
    month = {03},
    abstract = "{Common tasks encountered in epidemiology, including disease incidence estimation and causal inference, rely on predictive modelling. Constructing a predictive model can be thought of as learning a prediction function (a function that takes as input covariate data and outputs a predicted value). Many strategies for learning prediction functions from data (learners) are available, from parametric regressions to machine learning algorithms. It can be challenging to choose a learner, as it is impossible to know in advance which one is the most suitable for a particular dataset and prediction task. The super learner (SL) is an algorithm that alleviates concerns over selecting the one ‘right’ learner by providing the freedom to consider many, such as those recommended by collaborators, used in related research or specified by subject-matter experts. Also known as stacking, SL is an entirely prespecified and flexible approach for predictive modelling. To ensure the SL is well specified for learning the desired prediction function, the analyst does need to make a few important choices. In this educational article, we provide step-by-step guidelines for making these decisions, walking the reader through each of them and providing intuition along the way. In doing so, we aim to empower the analyst to tailor the SL specification to their prediction task, thereby ensuring their SL performs as well as possible. A flowchart provides a concise, easy-to-follow summary of key suggestions and heuristics, based on our accumulated experience and guided by SL optimality theory.}",
    issn = {0300-5771},
    doi = {10.1093/ije/dyad023},
    url = {https://doi.org/10.1093/ije/dyad023},
    eprint = {https://academic.oup.com/ije/article-pdf/52/4/1276/51027197/dyad023.pdf},
}
@article {deltaMethod,
	AUTHOR = {Doob, Joseph L.},
	TITLE = {The limiting distributions of certain
		 statistics},
	JOURNAL = {Annals of Mathematical Statistics},
	VOLUME = {6},
	NUMBER = {3},
	MONTH = {September},
	YEAR = {1935},
	PAGES = {160--169},
	URL = {https://www.jstor.org/stable/2957546},
	NOTE = {Zbl:0012.26801. JFM:61.1296.01.},
	ISSN = {0003-4851},
}
@book{asymptotic,
title = {Asymptotic Statistics},
author = {Vaart, A. W. van der},
year = {2000},
publisher = {Cambridge University Press},
abstract = {This book is an introduction to the field of asymptotic statistics. The treatment is both practical and mathematically rigorous. In addition to most of the standard topics of an asymptotics course, including likelihood inference, M-estimation, the theory of asymptotic efficiency, U-statistics, and rank procedures, the book also presents recent research topics such as semiparametric models, the bootstrap, and empirical processes and their applications. The topics are organized from the central idea of approximation by limit experiments, which gives the book one of its unifying themes. This entails mainly the local approximation of the classical i.i.d. set up with smooth parameters by location experiments involving a single, normally distributed observation. Thus, even the standard subjects of asymptotic statistics are presented in a novel way. Suitable as a graduate or Master's level statistics text, this book will also give researchers an overview of research in asymptotic statistics.},
url = {https://EconPapers.repec.org/RePEc:cup:cbooks:9780521784504}
}
@article{fisher2021visually,
  title={Visually communicating and teaching intuition for influence functions},
  author={Fisher, Aaron and Kennedy, Edward H},
  journal={The American Statistician},
  volume={75},
  number={2},
  pages={162--172},
  year={2021},
  publisher={Taylor \& Francis}
}
@article{hines2022demystifying,
  title={Demystifying statistical learning based on efficient influence functions},
  author={Hines, Oliver and Dukes, Oliver and Diaz-Ordaz, Karla and Vansteelandt, Stijn},
  journal={The American Statistician},
  volume={76},
  number={3},
  pages={292--304},
  year={2022},
  publisher={Taylor \& Francis}
}
@misc{ilustrated,
  title={An illustrated guide to TMLE, part I: introduction and motivation},
  url={https://www.khstats.com/blog/tmle/tutorial},
  journal={Kat’s Stats},
  author={Hoffman, Katherine},
  year={2020},
  month={Dec}
} 