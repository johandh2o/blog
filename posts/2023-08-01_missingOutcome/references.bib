%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{koller2009,
  author    = {Koller, Daphne and Friedman, Nir},
  title     = {Probabilistic Graphical Models: Principles and Techniques},
  year      = {2009},
  publisher = {MIT Press},
  address   = {Cambridge, MA},
  isbn      = {978-0-262-01319-2}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{vanderzander2014,
  author    = {{van der Zander}, Bram and Liskiewicz, Maciej and Textor, Johannes},
  title     = {Constructing separators and adjustment sets in ancestral graphs},
  booktitle = {Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence},
  year      = {2014},
  pages     = {907--916}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@conference{Karimietal23,
  title = {On the Relationship Between Explanation and Prediction: A Causal View},
  author = {Karimi, A.-H. and Muandet, K. and Kornblith, S. and Sch{\"o}lkopf, B. and Kim, B.},
  booktitle = {40th International Conference on Machine Learning (ICML)},
  month = jul,
  year = {2023},
  doi = {},
  month_numeric = {7}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{pearl2018book,
  author       = {Pearl, Judea and Mackenzie, Dana},
  title        = {The Book of Why: The New Science of Cause and Effect},
  year         = {2018},
  publisher    = {Basic Books},
  address      = {New York},
  isbn         = {978-0465097609}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Scholkopf2012,
    author = {Sch\"{o}lkopf, Bernhard and Janzing, Dominik and Peters, Jonas and Sgouritsa, Eleni and Zhang, Kun and Mooij, Joris},
    title = {On Causal and Anticausal Learning},
    year = {2012},
    isbn = {9781450312851},
    publisher = {Omnipress},
    address = {Madison, WI, USA},
    abstract = {We consider the problem of function estimation in the case where an underlying causal model can be inferred. This has implications for popular scenarios such as covariate shift, concept drift, transfer learning and semi-supervised learning. We argue that causal knowledge may facilitate some approaches for a given problem, and rule out others. In particular, we formulate a hypothesis for when semi-supervised learning can help, and corroborate it with empirical results.},
    booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
    pages = {459–466},
    numpages = {8},
    location = {Edinburgh, Scotland},
    series = {ICML'12}
    }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Pearl7Tools,
    author = {Pearl, Judea},
    title = {The Seven Tools of Causal Inference, with Reflections on Machine Learning},
    year = {2019},
    issue_date = {March 2019},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {62},
    number = {3},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/3241036},
    doi = {10.1145/3241036},
    abstract = {The kind of causal inference seen in natural human thought can be "algorithmitized" to help produce human-level machine intelligence.},
    journal = {Commun. ACM},
    month = {feb},
    pages = {54–60},
    numpages = {7}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{Spirtes2000,
  added-at = {2009-09-12T19:19:34.000+0200},
  author = {Spirtes, P. and Glymour, C. and Scheines, R.},
  biburl = {https://www.bibsonomy.org/bibtex/2e2b107e8fd3469c8b0e944ca37a559f3/mozaher},
  edition = {2nd},
  interhash = {559e17fcd12a76214629ba6c4efe3f9a},
  intrahash = {e2b107e8fd3469c8b0e944ca37a559f3},
  keywords = {imported},
  owner = {Mozaherul Hoque},
  publisher = {MIT press},
  review = {PC algorithm},
  timestamp = {2009-09-12T19:19:43.000+0200},
  title = {Causation, Prediction, and Search},
  year = 2000
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inbook{BareinboimHierarchy2022,
    author = {Bareinboim, Elias and Correa, Juan D. and Ibeling, Duligur and Icard, Thomas},
    title = {On Pearl’s Hierarchy and the foundations of causal inference},
    year = {2022},
    isbn = {9781450395861},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    edition = {1},
    url = {https://doi.org/10.1145/3501714.3501743},
    booktitle = {Probabilistic and Causal Inference: The Works of Judea Pearl},
    pages = {507–556},
    numpages = {50}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{PearlCausality,
    abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research.},
    added-at = {2018-09-17T16:24:20.000+0200},
    address = {Cambridge, UK},
    author = {Pearl, Judea},
    biburl = {https://www.bibsonomy.org/bibtex/2378bd006b231f81cddd091429ceb0f80/flint63},
    doi = {10.1017/CBO9780511803161},
    edition = 2,
    file = {2009/Pearl09.pdf},
    interhash = {e7828b9bdefba2511eb63114c0c32b1b},
    intrahash = {378bd006b231f81cddd091429ceb0f80},
    isbn = {978-0-521-89560-6},
    isbn10 = {052189560X},
    keywords = {01901 103 ai algorithm book knowledge numerical processing theory},
    language = {american},
    owner = {flint},
    publisher = {Cambridge University Press},
    sortdate = {2009-12-01},
    subtitle = {Models, Reasoning, and Inference},
    timestamp = {2018-09-17T16:24:20.000+0200},
    title = {Causality},
    year = 2009
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{PearlPrimer,
    author = {Pearl, Judea},
    address = {Chichester, West Sussex},
    booktitle = {Causal inference in statistics: a primer},
    isbn = {9781119186847},
    keywords = {Causation},
    language = {eng},
    lccn = {2015033010},
    publisher = {Wiley},
    title = {Causal inference in statistics: a primer},
    year = 2016
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{PearlDo,
    author = {Pearl, Judea},
    title = {The Do-Calculus Revisited},
    year = {2012},
    isbn = {9780974903989},
    publisher = {AUAI Press},
    address = {Arlington, Virginia, USA},
    abstract = {The do-calculus was developed in 1995 to facilitate the identification of causal effects in non-parametric models. The completeness proofs of [Huang and Valtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of [Tian and Shpitser, 2010] have laid this identification problem to rest. Recent explorations unveil the usefulness of the do-calculus in three additional areas : mediation analysis [Pearl, 2012], transportability [Pearl and Bareinboim, 2011] and meta-synthesis. Meta-synthesis (freshly coined) is the task of fusing empirical results from several diverse studies, conducted on heterogeneous populations and under different conditions, so as to synthesize an estimate of a causal relation in some target environment, potentially different from those under study. The talk surveys these results with emphasis on the challenges posed by meta-synthesis. For background material, see (http://bayes.cs.ucla.edu/csl_papers.html).},
    booktitle = {Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence},
    pages = {3–11},
    numpages = {9},
    location = {Catalina Island, CA},
    series = {UAI'12}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{HuangComplete,
    author = {Huang, Yimin and Valtorta, Marco},
    title = {Pearl's Calculus of Intervention is Complete},
    year = {2006},
    isbn = {0974903922},
    publisher = {AUAI Press},
    address = {Arlington, Virginia, USA},
    abstract = {This paper is concerned with graphical criteria that can be used to solve the problem of identifying casual effects from nonexperimental data in a causal Bayesian network structure, i.e., a directed acyclic graph that represents causal relationships. We first review Pearl's work on this topic [Pearl, 1995], in which several useful graphical criteria are presented. Then we present a complete algorithm [Huang and Valtorta, 2006b] for the identifiability problem. By exploiting the completeness of this algorithm, we prove that the three basic do-calculus rules that Pearl presents are complete, in the sense that, if a causal effect is identifiable, there exists a sequence of applications of the rules of the do-calculus that transforms the causal effect formula into a formula that only includes observational quantities.},
    booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
    pages = {217–224},
    numpages = {8},
    location = {Cambridge, MA, USA},
    series = {UAI'06}
}
%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{ShpitserPearl06,
    author = {Shpitser, Ilya and Pearl, Judea},
    title = {Identification of Joint Interventional Distributions in Recursive Semi-Markovian Causal Models},
    year = {2006},
    isbn = {9781577352815},
    publisher = {AAAI Press},
    abstract = {This paper is concerned with estimating the effects of actions from causal assumptions, represented concisely as a directed graph, and statistical knowledge, given as a probability distribution. We provide a necessary and sufficient graphical condition for the cases when the causal effect of an arbitrary set of variables on another arbitrary set can be determined uniquely from the available information, as well as an algorithm which computes the effect whenever this condition holds. Furthermore, we use our results to prove completeness of do-calculus [Pearl, 1995], and a version of an identification algorithm in [Tian, 2002] for the same identification problem. Finally, we derive a complete characterization of semi-Markovian models in which all causal effects are identifiable.},
    booktitle = {Proceedings of the 21st National Conference on Artificial Intelligence - Volume 2},
    pages = {1219–1226},
    numpages = {8},
    location = {Boston, Massachusetts},
    series = {AAAI'06}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Brito2002,
    author = {Brito, Carlos and Pearl, Judea},
    title = {Generalized Instrumental Variables},
    year = {2002},
    isbn = {1558608974},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
    abstract = {This paper concerns the assessment of direct causal effects from a combination of: (i) nonexperimental data, and (ii) qualitative domain knowledge. Domain knowledge is encoded in the form of a directed acyclic graph (DAG), in which all interactions are assumed linear, and some variables are presumed to be unobserved. We provide a generalization of the well-known method of Instrumental Variables, which allows its application to models with few conditional independeces.},
    booktitle = {Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence},
    pages = {85–93},
    numpages = {9},
    location = {Alberta, Canada},
    series = {UAI'02}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Bareinboim_Tian_Pearl_2014,
    title={Recovering from Selection Bias in Causal and Statistical Inference},
    volume={28},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/9074},
    DOI={10.1609/aaai.v28i1.9074},
    abstractNote={Selection bias is caused by preferential exclusion of units from the samples and represents a major obstacle to valid causal and statistical inferences; it cannot be removed by randomized experiments and can rarely be detected in either experimental or observational studies. In this paper, we provide complete graphical and algorithmic conditions for recovering conditional probabilities from selection biased data. We also provide graphical conditions for recoverability when unbiased data is available over a subset of the variables. Finally, we provide a graphical condition that generalizes the backdoor criterion and serves to recover causal effects when the data is collected under preferential selection}, number={1},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Bareinboim, Elias and Tian, Jin and Pearl, Judea},
    year={2014},
    month={Jun.}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Bareinboim_Tian_2015,
    title={Recovering Causal Effects from Selection Bias},
    volume={29},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/9679},
    DOI={10.1609/aaai.v29i1.9679},
    abstractNote={Controlling for selection and confounding biases are two of the most challenging problems that appear in data analysis in the empirical sciences as well as in artificial intelligence tasks. The combination of previously studied methods for each of these biases in isolation is not directly applicable to certain non-trivial cases in which selection and confounding biases are simultaneously present. In this paper, we tackle these instances non-parametrically and in full generality. We provide graphical and algorithmic conditions for recoverability of interventional distributions for when selection and confounding biases are both present. Our treatment completely characterizes the class of causal effects that are recoverable in Markovian models, and is suffi- cient for Semi-Markovian models.},
    number={1},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Bareinboim, Elias and Tian, Jin},
    year={2015},
    month={Mar.}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Balke97,
    author = { Alexander   Balke  and  Judea   Pearl },
    title = {Bounds on Treatment Effects from Studies with Imperfect Compliance},
    journal = {Journal of the American Statistical Association},
    volume = {92},
    number = {439},
    pages = {1171-1176},
    year  = {1997},
    publisher = {Taylor & Francis},
    doi = {10.1080/01621459.1997.10474074},
    URL = {
            https://doi.org/10.1080/01621459.1997.10474074
    },
    eprint = {
            https://doi.org/10.1080/01621459.1997.10474074
    }
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@InProceedings{Bareinboim12,
  title = 	 {Controlling Selection Bias in Causal Inference},
  author = 	 {Bareinboim, Elias and Pearl, Judea},
  booktitle = 	 {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {100--108},
  year = 	 {2012},
  editor = 	 {Lawrence, Neil D. and Girolami, Mark},
  volume = 	 {22},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {La Palma, Canary Islands},
  month = 	 {21--23 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v22/bareinboim12/bareinboim12.pdf},
  url = 	 {https://proceedings.mlr.press/v22/bareinboim12.html},
  abstract = 	 {Selection bias, caused by preferential exclusion of samples from the data, is a major obstacle to valid causal and statistical inferences; it cannot be removed by randomized experiments and can hardly be detected  in either experimental or observational studies. This paper highlights several graphical and algebraic methods capable of mitigating and sometimes eliminating this bias. These nonparametric methods generalize previously reported results, and identify the type of knowledge that is needed for reasoning in the presence of selection bias.  Specifically,  we derive a general condition together with a procedure for  deciding recoverability of the odds ratio (OR) from s-biased data. We show that recoverability  is feasible if and only if our condition holds.  We further offer a new method of controlling selection bias using instrumental variables that permits the  recovery of other effect measures besides OR.}
}
%%%%%%%%%%%
@book{Anastasios,
  title     = {Dynamic Treatment Regimes:
Statistical Methods for Precision Medicine},
  author    = {Anastasios Tsiatis and Marie Davidian and Shannon Holloway and Eric Laber},
  year      = 2019,
  publisher = {Chapman and Hall/CRC},
  address   = {New York, NY, USA},
  edition = {1},
  URL = {https://doi.org/10.1201/9780429192692},
  DOI = {10.1201/9780429192692},
  isbn = {9780429192692}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{BellmanDP,
  abstract = {An introduction to the mathematical theory of multistage decision processes, this text takes a "functional equation" approach to the discovery of optimum policies. Written by a leading developer of such policies, it presents a series of methods, uniqueness and existence theorems, and examples for solving the relevant equations. The text examines existence and uniqueness theorems, the optimal inventory equation, bottleneck problems in multistage production processes, a new formalism in the calculus of variation, strategies behind multistage games, and Markovian decision processes. Each chapter concludes with a problem set that Eric V. Denardo of Yale University, in his informative new introduction, calls "a rich lode of applications and research topics." 1957 edition. 37 figures.},
  added-at = {2011-08-17T16:08:47.000+0200},
  author = {Bellman, Richard},
  biburl = {https://www.bibsonomy.org/bibtex/29cdd821222218ded252c8ba5cd712666/pcbouman},
  interhash = {acf948462171ca060064a7ded257a792},
  intrahash = {9cdd821222218ded252c8ba5cd712666},
  isbn = {9780486428093},
  keywords = {book dynamic programming},
  publisher = {Dover Publications},
  timestamp = {2011-08-18T09:10:27.000+0200},
  title = {{Dynamic Programming}},
  year = 1957
}
%%%%%%%%%%%%%%%%%%%%%%%
@book{Puterman2014,
  added-at = {2017-04-07T12:13:11.000+0200},
  author = {Puterman, Martin L},
  biburl = {https://www.bibsonomy.org/bibtex/22e7ac99cd30c4892171e5a7cef1bc7a7/becker},
  interhash = {6cec8f775a265d8741171d17e4a4e7d0},
  intrahash = {2e7ac99cd30c4892171e5a7cef1bc7a7},
  keywords = {inthesis diss markov chain decision process citedby:scholar:count:9594 citedby:scholar:timestamp:2017-4-7},
  publisher = {John Wiley \& Sons},
  timestamp = {2017-04-07T12:13:11.000+0200},
  title = {Markov decision processes: discrete stochastic dynamic programming},
  year = 2014
}
%%%%%%%%%%%%%%%%%%
@article{Jung_Tian_Bareinboim_20,
    title={Estimating Causal Effects Using Weighting-Based Estimators},
    volume={34},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/6579},
    DOI={10.1609/aaai.v34i06.6579},
    abstractNote={Causal effect identification is one of the most prominent and well-understood problems in causal inference. Despite the generality and power of the results developed so far, there are still challenges in their applicability to practical settings, arguably due to the finitude of the samples. Simply put, there is a gap between causal effect identification and estimation. One popular setting in which sample-efficient estimators from finite samples exist is when the celebrated back-door condition holds. In this paper, we extend weighting-based methods developed for the back-door case to more general settings, and develop novel machinery for estimating causal effects using the weighting-based method as a building block. We derive graphical criteria under which causal effects can be estimated using this new machinery and demonstrate the effectiveness of the proposed method through simulation studies.},
    number={06},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Jung, Yonghan and Tian, Jin and Bareinboim, Elias},
    year={2020}, month={Apr.},
    pages={10186-10193}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Correa_Tian_Bareinboim_2018,
    title={Generalized Adjustment Under Confounding and Selection Biases},
    volume={32},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/12125},
    DOI={10.1609/aaai.v32i1.12125},
    abstractNote={Selection and confounding biases are the two most common impediments to the applicability of causal inference methods in large-scale settings. We generalize the notion of backdoor adjustment to account for both biases and leverage external data that may be available without selection bias (e.g., data from census). We introduce the notion of adjustment pair and present complete graphical conditions for identifying causal effects by adjustment. We further design an algorithm for listing all admissible adjustment pairs in polynomial delay, which is useful for researchers interested in evaluating certain properties of some admissible pairs but not all (common properties include cost, variance, and feasibility to measure). Finally, we describe a statistical estimation procedure that can be performed once a set is known to be admissible, which entails different challenges in terms of finite samples.},
    number={1},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Correa, Juan and Tian, Jin and Bareinboim, Elias},
    year={2018}, month={Apr.}
    }
%%%%%%%%%%%%%
@article{Correa_Tian_Bareinboim_2019,
    title={Identification of Causal Effects in the Presence of Selection Bias},
    volume={33},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/4125}, DOI={10.1609/aaai.v33i01.33012744},
    abstractNote={Cause-and-effect relations are one of the most valuable types of knowledge sought after throughout the data-driven sciences since they translate into stable and generalizable explanations as well as efficient and robust decision-making capabilities. Inferring these relations from data, however, is a challenging task. Two of the most common barriers to this goal are known as confounding and selection biases. The former stems from the systematic bias introduced during the treatment assignment, while the latter comes from the systematic bias during the collection of units into the sample. In this paper, we consider the problem of identifiability of causal effects when both confounding and selection biases are simultaneously present. We first investigate the problem of identifiability when all the available data is biased. We prove that the algorithm proposed by [Bareinboim and Tian, 2015] is, in fact, complete, namely, whenever the algorithm returns a failure condition, no identifiability claim about the causal relation can be made by any other method. We then generalize this setting to when, in addition to the biased data, another piece of external data is available, without bias. It may be the case that a subset of the covariates could be measured without bias (e.g., from census). We examine the problem of identifiability when a combination of biased and unbiased data is available. We propose a new algorithm that subsumes the current state-of-the-art method based on the back-door criterion.},
    number={01},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Correa, Juan D. and Tian, Jin and Bareinboim, Elias},
    year={2019},
    month={Jul.},
    pages={2744-2751}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
@InProceedings{Correa2019,
  title = 	 {Adjustment Criteria for Generalizing Experimental Findings},
  author =       {Correa, Juan and Tian, Jin and Bareinboim, Elias},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {1361--1369},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/correa19a/correa19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/correa19a.html},
  abstract = 	 {Generalizing causal effects from a controlled experiment to settings beyond the particular study population is arguably one of the central tasks found in empirical circles. While a proper design and careful execution of the experiment would support, under mild conditions, the validity of inferences about the population in which the experiment was conducted, two challenges make the extrapolation step to different populations somewhat involved, namely, transportability and sampling selection bias. The former is concerned with disparities in the distributions and causal mechanisms between the domain (i.e., settings, population, environment) where the experiment is conducted and where the inferences are intended; the latter with distortions in the sample’s proportions due to preferential selection of units into the study. In this paper, we investigate the assumptions and machinery necessary for using <em>covariate adjustment</em> to correct for the biases generated by both of these problems, and generalize experimental data to infer causal effects in a new domain. We derive complete graphical conditions to determine if a set of covariates is admissible for adjustment in this new setting. Building on the graphical characterization, we develop an efficient algorithm that enumerates all possible admissible sets with poly-time delay guarantee; this can be useful for when some variables are preferred over the others due to different costs or amenability to measurement.}
}
%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Oset,
    author = {Witte, Janine and Henckel, Leonard and Maathuis, Marloes H. and Didelez, Vanessa},
    title = {On Efficient Adjustment in Causal Graphs},
    year = {2020},
    issue_date = {January 2020},
    publisher = {JMLR.org},
    volume = {21},
    number = {1},
    issn = {1532-4435},
    abstract = {We consider estimation of a total causal effect from observational data via covariate adjustment. Ideally, adjustment sets are selected based on a given causal graph, reflecting knowledge of the underlying causal structure. Valid adjustment sets are, however, not unique. Recent research has introduced a graphical criterion for an 'optimal' valid adjustment set (O-set). For a given graph, adjustment by the O-set yields the smallest asymptotic variance compared to other adjustment sets in certain parametric and non-parametric models. In this paper, we provide three new results on the O-set. First, we give a novel, more intuitive graphical characterisation: We show that the O-set is the parent set of the outcome node(s) in a suitable latent projection graph, which we call the forbidden projection. An important property is that the forbidden projection preserves all information relevant to total causal effect estimation via covariate adjustment, making it a useful methodological tool in its own right. Second, we extend the existing IDA algorithm to use the O-set, and argue that the algorithm remains semi-local. This is implemented in the R-package pcalg. Third, we present assumptions under which the O-set can be viewed as the target set of popular non-graphical variable selection algorithms such as stepwise backward selection.},
    journal = {J. Mach. Learn. Res.},
    month = {jan},
    articleno = {246},
    numpages = {45},
    keywords = {causal discovery, sufficient adjustment set, model selection, IDA algorithm, graphical models, efficiency, confounding, confounder selection, causal inference}
}
%%%%%%%%%%%%%%%%%%%%%%
@article{Robins_1992,
 ISSN = {10443983},
 URL = {http://www.jstor.org/stable/3702894},
 abstract = {We consider the problem of separating the direct effects of an exposure from effects relayed through an intermediate variable (indirect effects). We show that adjustment for the intermediate variable, which is the most common method of estimating direct effects, can be biased. We also show that, even in a randomized crossover trial of exposure, direct and indirect effects cannot be separated without special assumptions; in other words, direct and indirect effects are not separately identifiable when only exposure is randomized. If the exposure and intermediate never interact to cause disease and if intermediate effects can be controlled, that is, blocked by a suitable intervention, then a trial randomizing both exposure and the intervention can separate direct from indirect effects. Nonetheless, the estimation must be carried out using the G-computation algorithm. Conventional adjustment methods remain biased. When exposure and the intermediate interact to cause disease, direct and indirect effects will not be separable even in a trial in which both the exposure and the intervention blocking intermediate effects are randomly assigned. Nonetheless, in such a trial, one can still estimate the fraction of exposure-induced disease that could be prevented by control of the intermediate. Even in the absence of an intervention blocking the intermediate effect, the fraction of exposure-induced disease that could be prevented by control of the intermediate can be estimated with the G-computation algorithm if data are obtained on additional confounding variables.},
 author = {James M. Robins and Sander Greenland},
 journal = {Epidemiology},
 number = {2},
 pages = {143--155},
 publisher = {Lippincott Williams & Wilkins},
 title = {Identifiability and Exchangeability for Direct and Indirect Effects},
 urldate = {2023-03-24},
 volume = {3},
 year = {1992}
}
%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Pearl_NDE_2001,
    author = {Pearl, Judea},
    title = {Direct and Indirect Effects},
    year = {2001},
    isbn = {1558608001},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
    abstract = {The direct effect of one event on another can be defined and measured by holding constant all intermediate variables between the two. Indirect effects present conceptual and practical difficulties (in nonlinear models), because they cannot be isolated by holding certain variables constant. This paper presents a new way of defining the effect transmitted through a restricted set of paths, without controlling variables on the remaining paths. This permits the assessment of a more natural type of direct and indirect effects, one that is applicable in both linear and nonlinear models and that has broader policy-related interpretations. The paper establishes conditions under which such assessments can be estimated consistently from experimental and nonexperimental data, and thus extends path-analytic techniques to nonlinear and nonparametric models.},
    booktitle = {Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence},
    pages = {411–420},
    numpages = {10},
    location = {Seattle, Washington},
    series = {UAI'01}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Pearl_NDE_2014,
    author = {Pearl, Judea},
    year = {2014},
    month = {06},
    pages = {},
    title = {Interpretation and Identification of Causal Mediation},
    volume = {19},
    journal = {Psychological methods},
    doi = {10.1037/a0036434}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{ShpitserVanderWeele_2011,
    url = {https://doi.org/10.2202/1557-4679.1297},
    title = {A Complete Graphical Criterion for the Adjustment Formula in Mediation Analysis},
    author = {Ilya Shpitser and Tyler J VanderWeele},
    volume = {7},
    number = {1},
    journal = {The International Journal of Biostatistics},
    doi = {doi:10.2202/1557-4679.1297},
    year = {2011},
    lastchecked = {2023-03-24}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inbook{Pearl_NDE_2022,
    author = {Pearl, Judea},
    title = {Direct and Indirect Effects},
    year = {2022},
    isbn = {9781450395861},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    edition = {1},
    url = {https://doi.org/10.1145/3501714.3501736},
    booktitle = {Probabilistic and Causal Inference: The Works of Judea Pearl},
    pages = {373–392},
    numpages = {20}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{wachter2017,
  title={Counterfactual explanations without opening the black box: Automated decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harvard Journal of Law \& Technology},
  volume={31},
  number={2},
  year={2018},
  url = {https://ssrn.com/abstract=3063289},
  doi = {10.2139/ssrn.3063289}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{hernan2020causal,
  title={Causal Inference: What If},
  author={Hern{\'a}n, Miguel A. and Robins, James M.},
  year={2020},
  publisher={Boca Raton: Chapman and Hall/CRC}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{vanderweele2013d,
  title={On the definition of a confounder},
  author={VanderWeele, Tyler J. and Shpitser, Ilya},
  journal={Annals of Statistics},
  volume={41},
  number={1},
  pages={196--220},
  year={2013},
  publisher={Institute of Mathematical Statistics}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{greenland2003,
  title={Quantifying biases in causal models: classical confounding vs collider-stratification bias},
  author={Greenland, Sander},
  journal={Epidemiology},
  volume={14},
  number={3},
  pages={300--306},
  year={2003},
  publisher={Lippincott Williams \& Wilkins}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{PearlRobins,
    author = {Pearl, Judea and Robins, James},
    title = {Probabilistic Evaluation of Sequential Plans from Causal Models with Hidden Variables},
    year = {1995},
    isbn = {1558603859},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
    abstract = {The paper concerns the probabilistic evaluation of plans in the presence of unmeasured variables, each plan consisting of several concurrent or sequential actions. We establish a graphical criterion for recognizing when the effects of a given plan can be predicted from passive observations on measured variables only. When the criterion is satisfied, a closed-form expression is provided for the probability that the plan will achieve a specified goal.},
    booktitle = {Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence},
    pages = {444–453},
    numpages = {10},
    keywords = {graphical models, sequential treatments, causal diagrams, causal effect, plan evaluation},
    location = {Montr\'{e}al, Qu\'{e}, Canada},
    series = {UAI'95}
}
%%%%%%%%%%%%%%%%%%
@article{Pearl1995,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2337329},
 abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained.},
 author = {Judea Pearl},
 journal = {Biometrika},
 number = {4},
 pages = {669--688},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Causal Diagrams for Empirical Research},
 urldate = {2023-06-02},
 volume = {82},
 year = {1995}
}
%%%%%%%%%%%%%%%%%%%
@InProceedings{gID2020,
  title = 	 {General Identifiability with Arbitrary Surrogate Experiments},
  author =       {Lee, Sanghack and Correa, Juan D. and Bareinboim, Elias},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages = 	 {389--398},
  year = 	 {2020},
  editor = 	 {Adams, Ryan P. and Gogate, Vibhav},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {22--25 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v115/lee20b/lee20b.pdf},
  url = 	 {https://proceedings.mlr.press/v115/lee20b.html},
  abstract = 	 {We study the problem of causal identification from an arbitrary collection of observational and experimental distributions, and substantive knowledge about the phenomenon under investigation, which usually comes in the form of a causal graph. We call this problem  \textit{g-identifiability}, or gID for short. The gID setting encompasses two  well-known problems in causal inference, namely, identifiability [Pearl, 1995] and z-identifiability [Bareinboim and Pearl, 2012] – the former assumes that an observational distribution is necessarily available, and no experiments can be performed, conditions that are both relaxed in the gID setting; the latter assumes that \textit{all} combinations of experiments are available, i.e., the power set of the experimental set $\mathbf{Z}$, which gID does not require a priori. In this paper, we introduce a general strategy to prove non-gID based on \textit{hedgelets} and \textit{thickets}, which leads to a necessary and sufficient graphical condition for the corresponding decision problem. We further develop a procedure for systematically computing the target effect, and prove that it is sound and complete for gID instances. In other words, failure of the algorithm in returning an expression implies that the target effect is not computable from the available distributions. Finally, as a corollary of these results, we show that do-calculus is complete for the task of g-identifiability.}
}
%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Shpitser2006,
    author = {Shpitser, Ilya and Pearl, Judea},
    title = {Identification of Conditional Interventional Distributions},
    year = {2006},
    isbn = {0974903922},
    publisher = {AUAI Press},
    address = {Arlington, Virginia, USA},
    abstract = {The subject of this paper is the elucidation of effects of actions from causal assumptions represented as a directed graph, and statistical knowledge given as a probability distribution. In particular, we are interested in predicting distributions on post-action outcomes given a set of measurements. We provide a necessary and sufficient graphical condition for the cases where such distributions can be uniquely computed from the available information, as well as an algorithm which performs this computation whenever the condition holds. Furthermore, we use our results to prove completeness of do-calculus [Pearl, 1995] for the same identification problem, and show applications to sequential decision making.},
    booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
    pages = {437–444},
    numpages = {8},
    location = {Cambridge, MA, USA},
    series = {UAI'06}
}
%%%%%%%%%%%%%%%%%%%%%%
@book{lash2021modern,
  title={Modern Epidemiology},
  author={Lash, Timothy L. and VanderWeele, Tyler J. and  Haneuse, Sebastien and Rothman, Kenneth J.},
  isbn={9781451193282},
  lccn={2020054540},
  year={2021},
  publisher={Wolters Kluwer},
  edition = {Fourth},
  address = {Philadelphia}
}
%%%%%%%%%%%%%%%%%%%%%%%%
@article{hernan2004structural,
  title={A structural approach to selection bias},
  author={Hern{\'a}n, Miguel A. and Hern{\'a}ndez-D{\'i}az, Sonia and Robins, James M.},
  journal={Epidemiology (Cambridge, Mass.)},
  volume={15},
  number={5},
  pages={615--625},
  year={2004},
  publisher={Lippincott Williams \& Wilkins},
  doi={10.1097/01.ede.0000135174.63482.43}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{biele2019bias,
  title={Bias from self selection and loss to follow-up in prospective cohort studies},
  author={Biele, Guido and Gustavson, Kristin and Czajkowski, Nikolai O. and Nilsen, Roy M. and Reichborn-Kjennerud, Ted and Magnus, Per M. and Stoltenberg, Camilla and Aase, Heidi},
  journal={European Journal of Epidemiology},
  volume={34},
  number={10},
  pages={927--938},
  year={2019},
  publisher={Springer},
  doi={10.1007/s10654-019-00550-1},
  note={PMID: 31451995}
}
%%%%%%%%%%%%%%%%%%
@article{westreich2012,
  title={Berkson's bias, selection bias, and missing data},
  author={Westreich, Daniel},
  journal={Epidemiology},
  volume={23},
  number={1},
  pages={159--164},
  year={2012},
  publisher={Lippincott Williams \& Wilkins},
  doi={10.1097/EDE.0b013e31823b6296},
  note={PMID: 22081062; PMCID: PMC3237868}
}
%%%%%%%%%%%%%%%
@article{flanders2019,
  title={Limits for the Magnitude of M-bias and Certain Other Types of Structural Selection Bias},
  author={Flanders, W. Dana and Ye, Dongni},
  journal={Epidemiology},
  volume={30},
  number={4},
  pages={501--508},
  year={2019},
  publisher={Lippincott Williams \& Wilkins},
  doi={10.1097/EDE.0000000000001031}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
@InProceedings{Pearl2013simple,
  title = 	 {A simple criterion for controlling selection bias},
  author = 	 {Chen, Eunice Yuh-Jie and Pearl, Judea},
  booktitle = 	 {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {170--177},
  year = 	 {2013},
  editor = 	 {Carvalho, Carlos M. and Ravikumar, Pradeep},
  volume = 	 {31},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Scottsdale, Arizona, USA},
  month = 	 {29 Apr--01 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v31/chen13b.pdf},
  url = 	 {https://proceedings.mlr.press/v31/chen13b.html},
  abstract = 	 {Controlling selection bias, a statistical error caused by preferential sampling of data, is a fundamental problem in machine learning and statistical inference. This paper presents a simple criterion for controlling selection bias in the odds ratio, a widely used measure for association between variables, that connects the nature of selection bias with the graph modeling the selection mechanism. If the graph contains certain paths, we show that the odds ratio cannot be expressed using data with selection bias. Otherwise, we show that a d-separability test can determine whether the odds ratio can be recovered, and when the answer is affirmative, output an unbiased estimand of the odds ratio. The criterion can be test in linear time and enhances the power of the estimand.}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{hernan2013,
	author = {Hern{\'a}n, Miguel A and Monge, Susana},
	title = {Selection bias due to conditioning on a collider},
	volume = {381},
	elocation-id = {p1135},
	year = {2023},
	doi = {10.1136/bmj.p1135},
	publisher = {BMJ Publishing Group Ltd},
	URL = {https://www.bmj.com/content/381/bmj.p1135},
	eprint = {https://www.bmj.com/content/381/bmj.p1135.full.pdf},
	journal = {BMJ}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Correa2017,
    author = {Correa, Juan D. and Bareinboim, Elias},
    title = {Causal Effect Identification by Adjustment under Confounding and Selection Biases},
    year = {2017},
    publisher = {AAAI Press},
    abstract = {Controlling for selection and confounding biases are two of the most challenging problems in the empirical sciences as well as in artificial intelligence tasks. Covariate adjustment (or, Backdoor Adjustment) is the most pervasive technique used for controlling confounding bias, but the same is oblivious to issues of sampling selection. In this paper, we introduce a generalized version of covariate adjustment that simultaneously controls for both confounding and selection biases. We first derive a sufficient and necessary condition for recovering causal effects using covariate adjustment from an observational distribution collected under preferential selection. We then relax this setting to consider cases when additional, unbiased measurements over a set of covariates are available for use (e.g., the age and gender distribution obtained from census data). Finally, we present a complete algorithm with polynomial delay to find all sets of admissible covariates for adjustment when confounding and selection biases are simultaneously present and unbiased data is available.},
    booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
    pages = {3740–3746},
    numpages = {7},
    location = {San Francisco, California, USA},
    series = {AAAI'17}
}
%%%%%%%
@inproceedings{ShpitserRobin10,
    author = {Shpitser, Ilya and VanderWeele, Tyler and Robins, James M.}, title = {On the Validity of Covariate Adjustment for Estimating Causal Effects}, year = {2010}, isbn = {9780974903965}, publisher = {AUAI Press}, address = {Arlington, Virginia, USA}, abstract = {Identifying effects of actions (treatments) on outcome variables from observational data and causal assumptions is a fundamental problem in causal inference. This identification is made difficult by the presence of con-founders which can be related to both treatment and outcome variables. Confounders are often handled, both in theory and in practice, by adjusting for covariates, in other words considering outcomes conditioned on treatment and covariate values, weighed by probability of observing those covariate values. In this paper, we give a complete graphical criterion for covariate adjustment, which we term the adjustment criterion, and derive some interesting corollaries of the completeness of this criterion.}, booktitle = {Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence}, pages = {527–536}, numpages = {10}, location = {Catalina Island, CA}, series = {UAI'10}
}
%%%%%%%%%%%%%%%%%%
@article{mgraphs,
    author = {Karthika Mohan and Judea Pearl},
    title = {Graphical Models for Processing Missing Data},
    journal = {Journal of the American Statistical Association},
    volume = {116},
    number = {534},
    pages = {1023-1037},
    year  = {2021},
    publisher = {Taylor & Francis},
    doi = {10.1080/01621459.2021.1874961},
    URL = {
            https://doi.org/10.1080/01621459.2021.1874961
    },
    eprint = {
            https://doi.org/10.1080/01621459.2021.1874961
    }
}
%%%%%%%%%%%%%%%%%
@article{Hernan2017,
    author = {Hernán, Miguel A.},
    title = "{Invited Commentary: Selection Bias Without Colliders}",
    journal = {American Journal of Epidemiology},
    volume = {185},
    number = {11},
    pages = {1048-1050},
    year = {2017},
    month = {05},
    abstract = "{In causal analyses, conditioning on a collider generally results in selection bias.
          Conditioning on a prognostic factor that is independent of the exposure—and therefore is
          not a collider—can also result in selection bias when 1) the exposure has a non-null
          effect on the outcome and 2) the association between the noncollider and the outcome is
          heterogenous across levels of the exposure. This result was empirically demonstrated by
          Greenland in 1977 (Am J Epidemiol. 1977;106(3):184–187).}",
    issn = {0002-9262},
    doi = {10.1093/aje/kwx077},
    url = {https://doi.org/10.1093/aje/kwx077},
    eprint = {https://academic.oup.com/aje/article-pdf/185/11/1048/29016569/kwx077.pdf},
}
%%%%%%%%%%%%%%%%%%
@article{Rubin1976,
  title={Inference and missing data},
  author={Rubin, Donald B},
  journal={Biometrika},
  volume={63},
  number={3},
  pages={581--592},
  year={1976},
  publisher={Oxford University Press}
}
%%%%%%%%%%%%%%%%%%
@article{RubinMIpaper,
  title={Multiple imputations in sample surveys: a phenomenological {B}ayesian approach to nonresponse},
  author={Rubin, Donald B},
  journal={Journal of the American Statistical Association},
  volume={73},
  number={362},
  pages={384--395},
  year={1978},
  publisher={Taylor \& Francis},
}
%%%%%%%%%%%%%%%%
@book{RubinMIbook,
  title={Multiple Imputation for Nonresponse in Surveys},
  author={Rubin, Donald B.},
  year={1987},
  publisher={John Wiley \& Sons},
}
%%%%%%%%%%%%%
@article{geneletti2009adjusting,
  title={Adjusting for selection bias in retrospective, case-control studies},
  author={Geneletti, Sara and Richardson, Sylvia and Best, Nicky},
  journal={Biostatistics},
  volume={10},
  number={1},
  pages={17--31},
  year={2009},
}
%%%%%%%%%%%%%%%%%
@article{didelez2010graphical,
  title={Graphical models for inference under outcome-dependent sampling},
  author={Didelez, V. and Kreiner, S. and Keiding, N.},
  journal={Statistical Science},
  volume={25},
  number={3},
  pages={368--387},
  year={2010},
}
%%%%%%%%%%%%%%%%%%%%%
@InProceedings{Bhattacharya2020,
  title = 	 {Identification In Missing Data Models Represented By Directed Acyclic Graphs},
  author =       {Bhattacharya, Rohit and Nabi, Razieh and Shpitser, Ilya and Robins, James M.},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages = 	 {1149--1158},
  year = 	 {2020},
  editor = 	 {Adams, Ryan P. and Gogate, Vibhav},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {22--25 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v115/bhattacharya20b/bhattacharya20b.pdf},
  url = 	 {https://proceedings.mlr.press/v115/bhattacharya20b.html},
  abstract = 	 {Missing data is a pervasive problem in data analyses, resulting in datasets that contain censored realizations of a target distribution. Many approaches to inference on the target distribution using censored observed data, rely on missing data models represented as a factorization with respect to a directed acyclic graph. In this paper we consider the identifiability of the target distribution within this class of models, and show that the most general identification strategies proposed so far retain a significant gap in that they fail to identify a wide class of identifiable distributions. To address this gap, we propose a new algorithm that significantly generalizes the types of manipulations used in the ID algorithm [14, 16], developed in the context of causal inference, in order to obtain identification.}
}
%%%%%%%%
@article{DEMP1977,
  added-at = {2013-07-02T15:06:42.000+0200},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  biburl = {https://www.bibsonomy.org/bibtex/220a2bf528cbc6504f573625ecb78362e/mjobst},
  interhash = {6a3c3e7e36b05f7855a57eab65f93593},
  intrahash = {20a2bf528cbc6504f573625ecb78362e},
  journal = {Journal of the Royal Statistical Society: Series B},
  keywords = {},
  owner = {plankensteiner},
  pages = {1-38},
  timestamp = {2013-07-02T15:06:42.000+0200},
  title = {Maximum likelihood from incomplete data via the {EM} algorithm},
  url = {http://web.mit.edu/6.435/www/Dempster77.pdf},
  volume = 39,
  year = 1977
}
%%%%%%%%%%%%%%%
@article{MIPW,
    author = {Perkins, Neil J and Cole, Stephen R and Harel, Ofer and Tchetgen Tchetgen, Eric J and Sun, BaoLuo and Mitchell, Emily M and Schisterman, Enrique F},
    title = "{Principled Approaches to Missing Data in Epidemiologic Studies}",
    journal = {American Journal of Epidemiology},
    volume = {187},
    number = {3},
    pages = {568-575},
    year = {2017},
    month = {11},
    abstract = "{Principled methods with which to appropriately analyze missing data have long existed; however, broad implementation of these methods remains challenging. In this and 2 companion papers (Am J Epidemiol. 2018;187(3):576–584 and Am J Epidemiol. 2018;187(3):585–591), we discuss issues pertaining to missing data in the epidemiologic literature. We provide details regarding missing-data mechanisms and nomenclature and encourage the conduct of principled analyses through a detailed comparison of multiple imputation and inverse probability weighting. Data from the Collaborative Perinatal Project, a multisite US study conducted from 1959 to 1974, are used to create a masked data-analytical challenge with missing data induced by known mechanisms. We illustrate the deleterious effects of missing data with naive methods and show how principled methods can sometimes mitigate such effects. For example, when data were missing at random, naive methods showed a spurious protective effect of smoking on the risk of spontaneous abortion (odds ratio (OR) = 0.43, 95\\% confidence interval (CI): 0.19, 0.93), while implementation of principled methods multiple imputation (OR = 1.30, 95\\% CI: 0.95, 1.77) or augmented inverse probability weighting (OR = 1.40, 95\\% CI: 1.00, 1.97) provided estimates closer to the “true” full-data effect (OR = 1.31, 95\\% CI: 1.05, 1.64). We call for greater acknowledgement of and attention to missing data and for the broad use of principled missing-data methods in epidemiologic research.}",
    issn = {0002-9262},
    doi = {10.1093/aje/kwx348},
    url = {https://doi.org/10.1093/aje/kwx348},
    eprint = {https://academic.oup.com/aje/article-pdf/187/3/568/24134556/kwx348.pdf},
}
%%%%%%%%%%%%%%
@article{EMMI,
  title={Principled missing data methods for researchers},
  author={Dong, Yiran and Peng, Chao-Ying Joanne},
  journal={SpringerPlus},
  volume={2},
  pages={1--17},
  year={2013},
  publisher={Springer}
}
%%%%%%%%%%%%%%%%%
@article{Robins1994,
  title={Estimation of regression coefficients when some regressors are not always observed},
  author={Robins, James and Rotnitzky, Andrea and Zhao, Lue},
  journal={Journal of the American Statistical Association},
  volume={89},
  number={427},
  pages={846--866},
  year={1994},
}
%%%%%%%%%%%%%%%%
@article{kang2007demystifying,
  title={Demystifying double robustness},
  author={Kang, Joseph and Schafer, Joseph},
  journal={Statistical Science},
  volume={22},
  number={4},
  pages={523--539},
  year={2007},
}
%%%%%%%%%%%%%%%%%
@article{seaman2013review,
  title={Review of inverse probability weighting for dealing with missing data},
  author={Seaman, Shaun R and White, Ian R},
  journal={Statistical Methods in Medical Research},
  volume={22},
  number={3},
  pages={278--295},
  year={2013},
}
%%%%%%%%%%%%%%%%%%%%%
@article{mcisaac2017,
  title={Statistical methods for incomplete data: Some results on model misspecification},
  author={McIsaac, Michelle and Cook, Richard J},
  journal={Statistical Methods in Medical Research},
  volume={26},
  number={1},
  pages={248--267},
  year={2017},
  doi={10.1177/0962280214544251},
  url={https://pubmed.ncbi.nlm.nih.gov/25063681/},
  pmid={25063681}
}
%%%%%%%%%%%%%%%%
@book{Tsiatis2007,
  title={Semiparametric Theory and Missing Data},
  author={Tsiatis, A.},
  isbn={9780387373454},
  lccn={2006921164},
  series={Springer Series in Statistics},
  url={https://books.google.no/books?id=xqZFi2EMB40C},
  year={2007},
  publisher={Springer New York}
}
%%%%%%%%%%%%%
@article{AIPW2017,
    author = {Sun, BaoLuo and Perkins, Neil J and Cole, Stephen R and Harel, Ofer and Mitchell, Emily M and Schisterman, Enrique F and Tchetgen Tchetgen, Eric J},
    title = "{Inverse-Probability-Weighted Estimation for Monotone and Nonmonotone Missing Data}",
    journal = {American Journal of Epidemiology},
    volume = {187},
    number = {3},
    pages = {585-591},
    year = {2017},
    month = {11},
    abstract = "{Missing data is a common occurrence in epidemiologic research. In this paper, 3 data sets with induced missing values from the Collaborative Perinatal Project, a multisite US study conducted from 1959 to 1974, are provided as examples of prototypical epidemiologic studies with missing data. Our goal was to estimate the association of maternal smoking behavior with spontaneous abortion while adjusting for numerous confounders. At the same time, we did not necessarily wish to evaluate the joint distribution among potentially unobserved covariates, which is seldom the subject of substantive scientific interest. The inverse probability weighting (IPW) approach preserves the semiparametric structure of the underlying model of substantive interest and clearly separates the model of substantive interest from the model used to account for the missing data. However, IPW often will not result in valid inference if the missing-data pattern is nonmonotone, even if the data are missing at random. We describe a recently proposed approach to modeling nonmonotone missing-data mechanisms under missingness at random to use in constructing the weights in IPW complete-case estimation, and we illustrate the approach using 3 data sets described in a companion article (Am J Epidemiol. 2018;187(3):568–575).}",
    issn = {0002-9262},
    doi = {10.1093/aje/kwx350},
    url = {https://doi.org/10.1093/aje/kwx350},
    eprint = {https://academic.oup.com/aje/article-pdf/187/3/585/24134641/kwx350tchetgenwebmaterialfinal.pdf},
}
%%%%%%%%%%%%%
@article{Harel2018,
  title={Multiple Imputation for Incomplete Data in Epidemiologic Studies},
  author={Harel, Ofer and others},
  journal={American Journal of Epidemiology},
  volume={187},
  number={3},
  pages={576--584},
  year={2018},
  doi={10.1093/aje/kwx349},
  url={https://doi.org/10.1093/aje/kwx349}
}
%%%%%%%%%%
@book{Laan2003unified,
  title={Unified Methods for Censored Longitudinal Data and Causality},
  author={{van der Laan}, M.J. and Robins, J.M.},
  year={2003},
  publisher={Springer-Verlag, New York}
}
%%%%%%%%%%%%
@article{stableIPW,
author = {Avagyan, Vahe and Vansteelandt, Stijn},
title = {Stable inverse probability weighting estimation for longitudinal studies},
journal = {Scandinavian Journal of Statistics},
volume = {48},
number = {3},
pages = {1046-1067},
keywords = {calibration estimation, covariate balancing, inverse probability weighting, propensity score},
doi = {https://doi.org/10.1111/sjos.12542},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12542},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/sjos.12542},
abstract = {Abstract We consider estimation of the average effect of time-varying dichotomous exposure on outcome using inverse probability weighting (IPW) under the assumption that there is no unmeasured confounding of the exposure–outcome association at each time point. Despite the popularity of IPW, its performance is often poor due to instability of the estimated weights. We develop an estimating equation-based strategy for the nuisance parameters indexing the weights at each time point, aimed at preventing highly volatile weights and ensuring the stability of IPW estimation. Our proposed approach targets the estimation of the counterfactual mean under a chosen treatment regime and requires fitting a separate propensity score model at each time point. We discuss and examine extensions to enable the fitting of marginal structural models using one propensity score model across all time points. Extensive simulation studies demonstrate adequate performance of our approach compared with the maximum likelihood propensity score estimator and the covariate balancing propensity score estimator.},
year = {2021}
}
%%%%%%%%%%%%%
@article{wasserman,
	an = {25652314},
	author = {Robins, James M and Hern{\'a}n, Miguel A and Wasserman, Larry},
	date = {2015/06/},
	date-added = {2022-04-02 21:29:05 +0200},
	date-modified = {2022-04-02 21:29:05 +0200},
	db = {PubMed},
	doi = {10.1111/biom.12273},
	edition = {2015/02/04},
	isbn = {1541-0420; 0006-341X},
	j2 = {Biometrics},
	journal = {Biometrics},
	keywords = {*Bayes Theorem; Humans},
	l2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4667748/},
	la = {eng},
	month = {06},
	number = {2},
	pages = {296--299},
	title = {Discussion of "On {B}ayesian estimation of marginal structural models"},
	u1 = {25652314{$[$}pmid{$]$}},
	u2 = {PMC4667748{$[$}pmcid{$]$}},
	url = {https://pubmed.ncbi.nlm.nih.gov/25652314},
	volume = {71},
	year = {2015},
	bdsk-url-1 = {https://pubmed.ncbi.nlm.nih.gov/25652314},
	bdsk-url-2 = {https://doi.org/10.1111/biom.12273}
}
%%%%%%%%%%%%%%%%%
@inproceedings{Mohan2013,
 author = {Mohan, Karthika and Pearl, Judea and Tian, Jin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Graphical Models for Inference with Missing Data},
 url = {https://proceedings.neurips.cc/paper_files/paper/2013/file/0ff8033cf9437c213ee13937b1c4c455-Paper.pdf},
 volume = {26},
 year = {2013}
}
%%%%%%%%%%%%%%%%%%
@inproceedings{Mohan2014,
 author = {Mohan, Karthika and Pearl, Judea},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Graphical Models for Recovering Probabilistic and Causal Queries from Missing Data},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/31839b036f63806cba3f47b93af8ccb5-Paper.pdf},
 volume = {27},
 year = {2014}
}
%%%%%%%%%%%
@article{seaman2012combining,
  title={Combining multiple imputation and inverse-probability weighting},
  author={Seaman, Shaun R and White, Ian R and Copas, Andrew J and Li, Lingling},
  journal={Biometrics},
  volume={68},
  number={1},
  pages={129--137},
  year={2012},
  doi={10.1111/j.1541-0420.2011.01666.x},
  url={https://doi.org/10.1111/j.1541-0420.2011.01666.x},
  pmid={22050039},
  pmcid={PMC3412287}
}
%%%%%%%%%%%%%%%%%
@article{han2016combining,
  title={Combining Inverse Probability Weighting and Multiple Imputation to Improve Robustness of Estimation},
  author={Han, P.},
  journal={Scandinavian Journal of Statistics},
  volume={43},
  pages={246--260},
  year={2016},
  doi={10.1111/sjos.12177}
}
%%%%%%%%%%%%%%%%%%%%%%
@article{lewin2018attrition,
  title={Attrition Bias Related to Missing Outcome Data: A Longitudinal Simulation Study},
  author={Lewin, A. and Brondeel, R. and Benmarhnia, T. and Thomas, F. and Chaix, B.},
  journal={Epidemiology},
  volume={29},
  number={1},
  pages={87--95},
  year={2018},
  doi={10.1097/EDE.0000000000000755}
}
%%%%%%%%%%%%%%%%%%%%%%%%%
@article{robins1992recovery,
  title={Recovery of information and adjustment for dependent censoring using surrogate markers, Aids Epidemiology, Methodological issues},
  author={Robins, James and Rotnitzky, Andrea},
  journal={Proceedings of the American Statistical Association. Boston: Birkhauser},
  pages={24--33},
  year={1992}
}
%%%%%%%%%%%%%%%%%%%%%
@inproceedings{cortes2008sample,
  title={Sample selection bias correction theory},
  author={Cortes, Corinna and Mohri, Mehryar and Riley, Michael and Rostamizadeh, Afshin},
  booktitle={International conference on algorithmic learning theory},
  pages={38--53},
  year={2008},
  organization={Springer}
}
%%%%%%%%%%%%%%%%%
@InProceedings{Malinsky,
  title = 	 {Causal inference with outcome-dependent missingness and self-censoring},
  author =       {Chen, Jacob M. and Malinsky, Daniel and Bhattacharya, Rohit},
  booktitle = 	 {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},
  pages = 	 {358--368},
  year = 	 {2023},
  editor = 	 {Evans, Robin J. and Shpitser, Ilya},
  volume = 	 {216},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {31 Jul--04 Aug},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v216/chen23f/chen23f.pdf},
  url = 	 {https://proceedings.mlr.press/v216/chen23f.html},
  abstract = 	 {We consider missingness in the context of causal inference when the outcome of interest may be missing. If the outcome directly affects its own missingness status, i.e., it is “self-censoring”, this may lead to severely biased causal effect estimates. Miao et al. (2015) proposed the shadow variable method to correct for bias due to self-censoring; however, verifying the required model assumptions can be difficult. Here, we propose a test based on a randomized incentive variable offered to encourage reporting of the outcome that can be used to verify identification assumptions that are sufficient to correct for both self-censoring and confounding bias. Concretely, the test confirms whether a given set of pre-treatment covariates is sufficient to block all backdoor paths between the treatment and outcome as well as all paths between the treatment and missingness indicator after conditioning on the outcome. We show that under these conditions, the causal effect is identified by using the treatment as a shadow variable, and it leads to an intuitive inverse probability weighting estimator that uses a product of the treatment and response weights. We evaluate the efficacy of our test and downstream estimator via simulations.}
}
%%%%%%%%%%%%%%%%
@article{miao2015,
  title={Identification, doubly robust estimation, and semiparametric efficiency theory of nonignorable missing data with a shadow variable},
  author={Miao, Wang and Liu, Lan and Tchetgen, Eric Tchetgen and Geng, Zhi},
  journal={arXiv preprint arXiv:1509.02556},
  year={2015}
}
%%%%%%%%%%%%%%%%
@article{MLMI,
author = {Paul T. {von Hippel} and Jonathan W. Bartlett},
title = {{Maximum Likelihood Multiple Imputation: Faster Imputations and Consistent Standard Errors Without Posterior Draws}},
volume = {36},
journal = {Statistical Science},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {400 -- 420},
keywords = {incomplete data, missing data},
year = {2021},
doi = {10.1214/20-STS793},
URL = {https://doi.org/10.1214/20-STS793}
}
%%%%%%%%%%%%%%%%%
@article{robins1986gcomp,
  title={A new approach to causal inference in mortality studies with a sustained exposure period—application to control of the healthy worker survivor effect},
  author={Robins, James},
  journal={Mathematical modelling},
  volume={7},
  number={9-12},
  pages={1393--1512},
  year={1986},
  publisher={Elsevier}
}
%%%%%%%%%%%%%
@article{hartley1971,
  title={The analysis of incomplete data},
  author={Hartley, HO and Hocking, RR},
  journal={Biometrics},
  pages={783--823},
  year={1971},
  publisher={JSTOR}
}
%%%%%%%%%%%%%%%
@article{enders2001primer,
  title={A primer on maximum likelihood algorithms available for use with missing data},
  author={Enders, Craig K},
  journal={Structural Equation Modeling},
  volume={8},
  number={1},
  pages={128--141},
  year={2001},
  publisher={Taylor \& Francis}
}
%%%%%%%%%%%%
@article{Fink,
	abstract = {A maximum likelihood method of estimating the parameters of the multiple factor model when data are missing from the sample is presented. A Monte Carlo study compares the method with 5 heuristic methods of dealing with the problem. The present method shows some advantage in accuracy of estimation over the heuristic methods but is considerably more costly computationally.},
	author = {Finkbeiner, Carl},
	date = {1979/12/01},
	date-added = {2023-08-16 23:15:32 +0200},
	date-modified = {2023-08-16 23:15:32 +0200},
	doi = {10.1007/BF02296204},
	id = {Finkbeiner1979},
	isbn = {1860-0980},
	journal = {Psychometrika},
	number = {4},
	pages = {409--420},
	title = {Estimation for the multiple factor model when data are missing},
	url = {https://doi.org/10.1007/BF02296204},
	volume = {44},
	year = {1979},
	bdsk-url-1 = {https://doi.org/10.1007/BF02296204}
}
%%%%%%%%%%%%%%%%%%%
@article{DML,
    author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
    title = "{Double/debiased machine learning for treatment and structural parameters}",
    journal = {The Econometrics Journal},
    volume = {21},
    number = {1},
    pages = {C1-C68},
    year = {2018},
    month = {01},
    abstract = "{We revisit the classic semi‐parametric problem of inference on a low‐dimensional parameter θ0 in the presence of high‐dimensional nuisance parameters η0. We depart from the classical setting by allowing for η0 to be so high‐dimensional that the traditional assumptions (e.g. Donsker properties) that limit complexity of the parameter space for this object break down. To estimate η0, we consider the use of statistical or machine learning (ML) methods, which are particularly well suited to estimation in modern, very high‐dimensional cases. ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice. However, both regularization bias and overfitting in estimating η0 cause a heavy bias in estimators of θ0 that are obtained by naively plugging ML estimators of η0 into estimating equations for θ0. This bias results in the naive estimator failing to be N−1/2 consistent, where N is the sample size. We show that the impact of regularization bias and overfitting on estimation of the parameter of interest θ0 can be removed by using two simple, yet critical, ingredients: (1) using Neyman‐orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate θ0; (2) making use of cross‐fitting, which provides an efficient form of data‐splitting. We call the resulting set of methods double or debiased ML (DML). We verify that DML delivers point estimators that concentrate in an N−1/2‐neighbourhood of the true parameter values and are approximately unbiased and normally distributed, which allows construction of valid confidence statements. The generic statistical theory of DML is elementary and simultaneously relies on only weak theoretical requirements, which will admit the use of a broad array of modern ML methods for estimating the nuisance parameters, such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. We illustrate the general theory by applying it to provide theoretical properties of the following: DML applied to learn the main regression parameter in a partially linear regression model; DML applied to learn the coefficient on an endogenous variable in a partially linear instrumental variables model; DML applied to learn the average treatment effect and the average treatment effect on the treated under unconfoundedness; DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.}",
    issn = {1368-4221},
    doi = {10.1111/ectj.12097},
    url = {https://doi.org/10.1111/ectj.12097},
    eprint = {https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf},
}
%%%%%%%%%%%%%%%%%%%%%
@book{TMLEbook1,
  title={Targeted Learning: Causal Inference for Observational and Experimental Data},
  author={{van der Laan}, M.J. and Rose, S.},
  isbn={9781441997821},
  lccn={2011930854},
  series={Springer Series in Statistics},
  url={https://books.google.no/books?id=RGnSX5aCAgQC},
  year={2011},
  publisher={Springer New York}
}
%%%%%%%%%%%%%%%%%%%
@article{deepmed,
  title={DeepMed: Semiparametric causal mediation analysis with debiased deep learning},
  author={Xu, Siqi and Liu, Lin and Liu, Zhonghua},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28238--28251},
  year={2022}
}
%%%%%%%%%%%
@article{xu2023disentangled,
  title={Disentangled Representation for Causal Mediation Analysis},
  author={Xu, Ziqi and Cheng, Debo and Li, Jiuyong and Liu, Jixue and Liu, Lin and Wang, Ke},
  journal={arXiv preprint arXiv:2302.09694},
  year={2023}
}
%%%%%%%%%%%%%%%
@article{semiparMediationTchetgen,
    author = {Eric J. Tchetgen Tchetgen and Ilya Shpitser},
    title = {Semiparametric theory for causal mediation analysis: Efficiency bounds, multiple robustness and sensitivity analysis},
    volume = {40},
    journal = {The Annals of Statistics},
    number = {3},
    publisher = {Institute of Mathematical Statistics},
    pages = {1816 -- 1845},
    keywords = {double robust, local efficiency, mediation analysis, Natural direct effects, natural indirect effects},
    year = {2012},
    doi = {10.1214/12-AOS990},
    URL = {https://doi.org/10.1214/12-AOS990}
}
%%%%%%%%%%%%%%%
@article{highMed,
    title = {A machine learning based approach towards high-dimensional mediation analysis},
    journal = {NeuroImage},
    volume = {268},
    pages = {119843},
    year = {2023},
    issn = {1053-8119},
    doi = {https://doi.org/10.1016/j.neuroimage.2022.119843},
    url = {https://www.sciencedirect.com/science/article/pii/S1053811922009648},
    author = {Tanmay Nath and Brian Caffo and Tor Wager and Martin A. Lindquist},
    keywords = {Machine learning, Deep learning, Mediation analysis, fMRI, Resting-state functional connectivity, Pain},
    abstract = {Mediation analysis is used to investigate the role of intermediate variables (mediators) that lie in the path between an exposure and an outcome variable. While significant research has focused on developing methods for assessing the influence of mediators on the exposure-outcome relationship, current approaches do not easily extend to settings where the mediator is high-dimensional. These situations are becoming increasingly common with the rapid increase of new applications measuring massive numbers of variables, including brain imaging, genomics, and metabolomics. In this work, we introduce a novel machine learning based method for identifying high dimensional mediators. The proposed algorithm iterates between using a machine learning model to map the high-dimensional mediators onto a lower-dimensional space, and using the predicted values as input in a standard three-variable mediation model. Hence, the machine learning model is trained to maximize the likelihood of the mediation model. Importantly, the proposed algorithm is agnostic to the machine learning model that is used, providing significant flexibility in the types of situations where it can be used. We illustrate the proposed methodology using data from two functional Magnetic Resonance Imaging (fMRI) studies. First, using data from a task-based fMRI study of thermal pain, we combine the proposed algorithm with a deep learning model to detect distributed, network-level brain patterns mediating the relationship between stimulus intensity (temperature) and reported pain at the single trial level. Second, using resting-state fMRI data from the Human Connectome Project, we combine the proposed algorithm with a connectome-based predictive modeling approach to determine brain functional connectivity measures that mediate the relationship between fluid intelligence and working memory accuracy. In both cases, our multivariate mediation model links exposure variables (thermal pain or fluid intelligence), high dimensional brain measures (single-trial brain activation maps or resting-state brain connectivity) and behavioral outcomes (pain report or working memory accuracy) into a single unified model. Using the proposed approach, we are able to identify brain-based measures that simultaneously encode the exposure variable and correlate with the behavioral outcome.}
}
